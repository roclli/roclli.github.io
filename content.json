{"meta":{"title":"测试人员修炼","subtitle":"测试人员的技术博客;交流请加QQ群:549576208","description":"My-Description","author":"roclli","url":"https://roclli.github.io"},"pages":[{"title":"All categories","date":"2017-12-13T05:45:59.000Z","updated":"2017-12-13T05:46:23.355Z","comments":true,"path":"categories/index.html","permalink":"https://roclli.github.io/categories/index.html","excerpt":"","text":""},{"title":"All tags","date":"2017-12-13T05:42:24.000Z","updated":"2017-12-13T05:43:55.160Z","comments":true,"path":"tags/index.html","permalink":"https://roclli.github.io/tags/index.html","excerpt":"","text":""}],"posts":[{"title":"PP4-Demo-sidecar-script-2","slug":"PP4-Demo-sidecar-script-2","date":"2017-12-13T05:31:45.000Z","updated":"2017-12-13T06:37:16.832Z","comments":true,"path":"2017/12/13/PP4-Demo-sidecar-script-2/","link":"","permalink":"https://roclli.github.io/2017/12/13/PP4-Demo-sidecar-script-2/","excerpt":"","text":"123456789101112131415161718192021222324node &#123;// checkout scm docker.image(&apos;mysql:5&apos;).withRun(&apos;-e &quot;MYSQL_ROOT_PASSWORD=my-secret-pw&quot;&apos;) &#123; c -&gt; docker.image(&apos;mysql:5&apos;).inside(&quot;--link $&#123;c.id&#125;:db&quot;) &#123; /* Wait until mysql service is up */ echo &quot;---1output cat /etc/os-release end---&quot; sh &quot;cat /etc/os-release&quot; echo &quot;---1output cat /etc/os-release end---&quot; sh &apos;while ! mysqladmin ping -hdb --silent; do sleep 1; done&apos; &#125; docker.image(&apos;centos:7&apos;).inside(&quot;--link $&#123;c.id&#125;:db&quot;) &#123; /* * Run some tests which require MySQL, and assume that it is * available on the host name `db` */// sh &apos;make check&apos; echo &quot;---2output cat /etc/os-release end---&quot; sh &quot;cat /etc/os-release&quot; echo &quot;---2output cat /etc/os-release end---&quot; echo &quot;---run test whcih require MySQL---&quot; &#125; &#125;&#125;","categories":[{"name":"Pipeline Code","slug":"Pipeline-Code","permalink":"https://roclli.github.io/categories/Pipeline-Code/"}],"tags":[{"name":"Jenkins Pipeline","slug":"Jenkins-Pipeline","permalink":"https://roclli.github.io/tags/Jenkins-Pipeline/"}]},{"title":"PP4-Demo-sidecar-script-1","slug":"PP4-Demo-sidecar-script-1","date":"2017-12-13T05:31:42.000Z","updated":"2017-12-13T06:37:05.193Z","comments":true,"path":"2017/12/13/PP4-Demo-sidecar-script-1/","link":"","permalink":"https://roclli.github.io/2017/12/13/PP4-Demo-sidecar-script-1/","excerpt":"","text":"123456789101112131415161718192021222324node &#123;// checkout scm /* * In order to communicate with the MySQL server, this Pipeline explicitly * maps the port (`3306`) to a known port on the host machine. */ docker.image(&apos;mysql:5&apos;).withRun(&apos;-e &quot;MYSQL_ROOT_PASSWORD=my-secret-pw&quot; -p 3306:3306&apos;) &#123; c -&gt; /* Wait until mysql service is up */// echo &quot;---start mysql---&quot;// sh &quot;service mysql start&quot; //shijianzhengming实践证明，不需要单独启动MySQL// sh &apos;while ! mysqladmin ping -h0.0.0.0 --silent; do sleep 1; done&apos;// echo &quot;---output pwd start---&quot;// sh &quot;pwd&quot;// echo &quot;---output pwd end---&quot;// sh &quot;cat /etc/os-release&quot;// echo &quot;---output cat /etc/os-release end---&quot; sh &apos;while ! mysqladmin ping -h0.0.0.0 --silent; do sleep 1; done&apos;// sh &quot;while ! /usr/bin/mysql -uroot -h0.0.0.0 -p my-secret-pw -e &apos;show databases&apos; --silent; do sleep 1; done&quot; /* Run some tests which require MySQL */// sh &apos;make check&apos; echo &quot;---run some tests which require MySQL---&quot; &#125;&#125;","categories":[{"name":"Pipeline","slug":"Pipeline","permalink":"https://roclli.github.io/categories/Pipeline/"}],"tags":[{"name":"Jenkins Pipeline","slug":"Jenkins-Pipeline","permalink":"https://roclli.github.io/tags/Jenkins-Pipeline/"}]},{"title":"PP4-Demo-dockerfile-declarative","slug":"PP4-Demo-dockerfile-declarative","date":"2017-12-13T05:29:50.000Z","updated":"2017-12-13T06:36:54.145Z","comments":true,"path":"2017/12/13/PP4-Demo-dockerfile-declarative/","link":"","permalink":"https://roclli.github.io/2017/12/13/PP4-Demo-dockerfile-declarative/","excerpt":"","text":"Jenkins代码详见：https://gitee.com/roclli/pp4-3-dockerfile.git Jenkinsfile内容为：12345678910111213141516pipeline &#123;// agent &#123; dockerfile true &#125; agent &#123; dockerfile &#123; additionalBuildArgs &apos;-t node-svn:7-alpine&apos; &#125; &#125; stages &#123; stage(&apos;Test&apos;) &#123; steps &#123; sh &apos;node --version&apos; sh &apos;svn --version&apos; &#125; &#125; &#125;&#125; Dockerfile12FROM node:7-alpineRUN apk add -U subversion","categories":[{"name":"Pipeline","slug":"Pipeline","permalink":"https://roclli.github.io/categories/Pipeline/"}],"tags":[{"name":"Jenkins Pipeline","slug":"Jenkins-Pipeline","permalink":"https://roclli.github.io/tags/Jenkins-Pipeline/"}]},{"title":"PP4-Demo-multip-container-script","slug":"PP4-Demo-multip-container-script","date":"2017-12-13T05:28:42.000Z","updated":"2017-12-13T06:37:01.129Z","comments":true,"path":"2017/12/13/PP4-Demo-multip-container-script/","link":"","permalink":"https://roclli.github.io/2017/12/13/PP4-Demo-multip-container-script/","excerpt":"","text":"1234567891011121314node &#123; /* Requires the Docker Pipeline plugin to be installed */ stage(&apos;Back-end&apos;) &#123; docker.image(&apos;maven:3-alpine&apos;).inside &#123; sh &apos;mvn --version&apos; &#125; &#125; stage(&apos;Front-end&apos;) &#123; docker.image(&apos;node:7-alpine&apos;).inside &#123; sh &apos;node --version&apos; &#125; &#125;&#125;","categories":[{"name":"Pipeline","slug":"Pipeline","permalink":"https://roclli.github.io/categories/Pipeline/"}],"tags":[{"name":"Jenkins Pipeline","slug":"Jenkins-Pipeline","permalink":"https://roclli.github.io/tags/Jenkins-Pipeline/"}]},{"title":"PP4-Demo-multip-container-declarative","slug":"PP4-Demo-multip-container-declarative","date":"2017-12-13T05:27:39.000Z","updated":"2017-12-13T06:36:57.449Z","comments":true,"path":"2017/12/13/PP4-Demo-multip-container-declarative/","link":"","permalink":"https://roclli.github.io/2017/12/13/PP4-Demo-multip-container-declarative/","excerpt":"","text":"Jenkins代码详见：https://gitee.com/roclli/pp4-2-multip-container Jenkinsfile内容为：123456789101112131415161718192021pipeline &#123; agent none stages &#123; stage(&apos;Back-end&apos;) &#123; agent &#123; docker &#123; image &apos;maven:3-alpine&apos; &#125; &#125; steps &#123; sh &apos;mvn --version&apos; &#125; &#125; stage(&apos;Front-end&apos;) &#123; agent &#123; docker &#123; image &apos;node:7-alpine&apos; &#125; &#125; steps &#123; sh &apos;node --version&apos; &#125; &#125; &#125;&#125;","categories":[{"name":"Pipeline","slug":"Pipeline","permalink":"https://roclli.github.io/categories/Pipeline/"}],"tags":[{"name":"Jenkins Pipeline","slug":"Jenkins-Pipeline","permalink":"https://roclli.github.io/tags/Jenkins-Pipeline/"}]},{"title":"PP4-Demo-cache-data-script","slug":"PP4-Demo-cache-data-script","date":"2017-12-13T05:26:57.000Z","updated":"2017-12-13T06:36:44.025Z","comments":true,"path":"2017/12/13/PP4-Demo-cache-data-script/","link":"","permalink":"https://roclli.github.io/2017/12/13/PP4-Demo-cache-data-script/","excerpt":"","text":"12345678910111213141516171819node &#123;// echo &quot;---$HOME---&quot;// echo &quot;---$HOME/.m2:/root/.m2---&quot;// echo &quot;---$M2_HOME/repo---&quot;// sh &quot;ls -lrt $M2_HOME/repo&quot; /* Requires the Docker Pipeline plugin to be installed 注意：正常情况下应该使用$HOME/.m2 我本地用的是用的是特殊的maven docker.image(&apos;maven:3-alpine&apos;).inside(&apos;-v $HOME/.m2:/root/.m2&apos;) &#123; */ docker.image(&apos;maven:3-alpine&apos;).inside(&apos;-v $M2_HOME/repo:/root/.m2&apos;) &#123;// checkout([$class: &apos;GitSCM&apos;, branches: [[name: &apos;*/master&apos;], doGenerateSubmoduleConfigurations: false, extensions: [], submoduleCfg: [], userRemoteConfigs: [[url: &apos;https://gitee.com/roclli/pp4-1-cache-data.git&apos;]]]) git url: &apos;https://gitee.com/roclli/pp4-1-cache-data.git&apos; stage(&apos;Build&apos;) &#123; //执行编译打包 sh &apos;mvn -D$HOME/.m2=/root/.m2 -DskipTests clean package&apos; &#125; &#125;&#125;","categories":[{"name":"Pipeline","slug":"Pipeline","permalink":"https://roclli.github.io/categories/Pipeline/"}],"tags":[{"name":"Jenkins Pipeline","slug":"Jenkins-Pipeline","permalink":"https://roclli.github.io/tags/Jenkins-Pipeline/"}]},{"title":"PP4-Demo-cache-data-declarative","slug":"PP4-Demo-cache-data-declarative","date":"2017-12-13T05:25:44.000Z","updated":"2017-12-13T06:36:40.701Z","comments":true,"path":"2017/12/13/PP4-Demo-cache-data-declarative/","link":"","permalink":"https://roclli.github.io/2017/12/13/PP4-Demo-cache-data-declarative/","excerpt":"","text":"Jenkins代码详见：https://gitee.com/roclli/pp4-1-cache-data.git Jenkinsfile内容为：1234567891011121314151617181920pipeline &#123; agent &#123; /* Requires the Docker Pipeline plugin to be installed 注意：正常情况下应该使用$HOME/.m2 我本地用的是用的是特殊的maven docker.image(&apos;maven:3-alpine&apos;).inside(&apos;-v $HOME/.m2:/root/.m2&apos;) &#123; */ docker &#123; image &apos;maven:3-alpine&apos; args &apos;-v $M2_HOME/repo:/root/.m2&apos; &#125; &#125; stages &#123; stage(&apos;Build&apos;) &#123; steps &#123; sh &apos;mvn -D$HOME/.m2=/root/.m2 -DskipTests clean package&apos; &#125; &#125; &#125;&#125;","categories":[{"name":"Pipeline","slug":"Pipeline","permalink":"https://roclli.github.io/categories/Pipeline/"}],"tags":[{"name":"Jenkins Pipeline","slug":"Jenkins-Pipeline","permalink":"https://roclli.github.io/tags/Jenkins-Pipeline/"}]},{"title":"PP4-Demo-custom-exec-env-script","slug":"PP4-Demo-custom-exec-env-script","date":"2017-12-13T05:24:56.000Z","updated":"2017-12-13T06:36:50.605Z","comments":true,"path":"2017/12/13/PP4-Demo-custom-exec-env-script/","link":"","permalink":"https://roclli.github.io/2017/12/13/PP4-Demo-custom-exec-env-script/","excerpt":"","text":"12345678node &#123; /* Requires the Docker Pipeline plugin to be installed */ docker.image(&apos;node:7-alpine&apos;).inside &#123; stage(&apos;Test&apos;) &#123; sh &apos;node --version&apos; &#125; &#125;&#125;","categories":[{"name":"Pipeline","slug":"Pipeline","permalink":"https://roclli.github.io/categories/Pipeline/"}],"tags":[{"name":"Jenkins Pipeline","slug":"Jenkins-Pipeline","permalink":"https://roclli.github.io/tags/Jenkins-Pipeline/"}]},{"title":"PP4-Demo-custom-exec-env-declartive","slug":"PP4-Demo-custom-exec-env-declartive","date":"2017-12-13T05:23:21.000Z","updated":"2017-12-13T06:36:47.353Z","comments":true,"path":"2017/12/13/PP4-Demo-custom-exec-env-declartive/","link":"","permalink":"https://roclli.github.io/2017/12/13/PP4-Demo-custom-exec-env-declartive/","excerpt":"","text":"Jenkins代码详见：https://gitee.com/roclli/pp4-0-custom-exec-env Jenkinsfile内容为：1234567891011121314#!/usr/bing/env groovypipeline &#123; agent &#123; docker &#123; image &apos;node:7-alpine&apos; &#125; &#125; stages &#123; stage(&apos;Test&apos;) &#123; steps &#123; sh &apos;node --version&apos; &#125; &#125; &#125;&#125;","categories":[{"name":"Pipeline","slug":"Pipeline","permalink":"https://roclli.github.io/categories/Pipeline/"}],"tags":[{"name":"Jenkins Pipeline","slug":"Jenkins-Pipeline","permalink":"https://roclli.github.io/tags/Jenkins-Pipeline/"}]},{"title":"PP3-Demo-MultiBranch-Pipeline","slug":"PP3-Demo-MultiBranch-Pipeline","date":"2017-12-13T05:21:59.000Z","updated":"2017-12-13T06:36:37.017Z","comments":true,"path":"2017/12/13/PP3-Demo-MultiBranch-Pipeline/","link":"","permalink":"https://roclli.github.io/2017/12/13/PP3-Demo-MultiBranch-Pipeline/","excerpt":"","text":"Jenkins代码详见：https://gitee.com/roclli/simple-maven-project-with-tests.git Jenkinsfile内容为：1234567891011121314151617181920212223242526272829#!/usr/bing/env groovynode(&apos;master&apos;) &#123; echo &quot;----------------------start git url----------------------&quot; checkout scm// git url: &apos;https://gitee.com/roclli/simple-maven-project-with-tests.git&apos; echo &quot;----------------------version()----------------------&quot; def v = version() if (v) &#123; echo &quot;---Building version $&#123;v&#125;---&quot; &#125; def mvnHome = tool &apos;M3&apos; echo &quot;----------------------mvn -B -D verify----------------------&quot; sh &quot;$&#123;mvnHome&#125;/bin/mvn -B -Dmaven.test.failure.ignore verify&quot;&#125;def version() &#123; def matcher = readFile(&apos;pom.xml&apos;) =~ &apos;&lt;version&gt;(.+)&lt;/version&gt;&apos; echo &quot;---$&#123;matcher[0][1]&#125;---&quot; //---1.0-SNAPSHOT--- echo &quot;---$&#123;matcher[0][2]&#125;---&quot; //---null--- echo &quot;---$&#123;matcher[0][3]&#125;---&quot; //---null--- echo &quot;---$&#123;matcher[1][1]&#125;---&quot; //---2.18.1--- echo &quot;---$&#123;matcher[1][2]&#125;---&quot; //---null--- echo &quot;---$&#123;matcher[1][3]&#125;---&quot; //---null--- echo &quot;---$&#123;matcher[2][1]&#125;---&quot; //---4.11--- echo &quot;---$&#123;matcher[2][2]&#125;---&quot; //---null--- echo &quot;---$&#123;matcher[2][3]&#125;---&quot; //---null--- matcher ? matcher[0][1] : null&#125;","categories":[{"name":"Pipeline","slug":"Pipeline","permalink":"https://roclli.github.io/categories/Pipeline/"}],"tags":[{"name":"Jenkins Pipeline","slug":"Jenkins-Pipeline","permalink":"https://roclli.github.io/tags/Jenkins-Pipeline/"}]},{"title":"PP2-Demo-multipleagent-script","slug":"PP2-Demo-multipleagent-script","date":"2017-12-13T05:20:19.000Z","updated":"2017-12-13T06:36:10.790Z","comments":true,"path":"2017/12/13/PP2-Demo-multipleagent-script/","link":"","permalink":"https://roclli.github.io/2017/12/13/PP2-Demo-multipleagent-script/","excerpt":"","text":"12345678910111213141516171819202122232425262728293031323334353637383940414243node &#123; stage(&apos;Build&apos;) &#123; node &#123; echo &quot;---1in linux,start to checkout---&quot; checkout([$class: &apos;GitSCM&apos;, branches: [[name: &apos;*/master&apos;]], doGenerateSubmoduleConfigurations: false, extensions: [], submoduleCfg: [], userRemoteConfigs: [[url: &apos;https://gitee.com/roclli/9-multipleagent.git&apos;]]]) echo &quot;---1in linux,start to -B -Dmaven.test.failure.ignore verify---&quot; sh &quot;mvn -B -Dmaven.test.failure.ignore verify&quot; echo &quot;---1in linux,start to stash *.jar---&quot; stash includes: &apos;**/target/*.jar&apos;, name: &apos;app&apos; &#125; &#125; stage(&apos;Test&apos;) &#123; node(&apos;linux&apos;) &#123; echo &quot;---2in linux,start to checkout---&quot; checkout([$class: &apos;GitSCM&apos;, branches: [[name: &apos;*/master&apos;]], doGenerateSubmoduleConfigurations: false, extensions: [], submoduleCfg: [], userRemoteConfigs: [[url: &apos;https://gitee.com/roclli/9-multipleagent.git&apos;]]]) try &#123; echo &quot;---2in linux,start to unstash app---&quot; unstash &apos;app&apos; echo &quot;---2in linux,start to -B -Dmaven.test.failure.ignore verify---&quot; sh &quot;mvn -B -Dmaven.test.failure.ignore verify&quot; &#125; finally &#123; echo &quot;---2in linux,start to junit TEST-*.xml report---&quot; junit &apos;**/target/surefire-reports/TEST-*.xml&apos; &#125; &#125; node(&apos;windows&apos;) &#123; echo &quot;---3in windows,start to checkout---&quot; checkout([$class: &apos;GitSCM&apos;, branches: [[name: &apos;*/master&apos;]], doGenerateSubmoduleConfigurations: false, extensions: [], submoduleCfg: [], userRemoteConfigs: [[url: &apos;https://gitee.com/roclli/9-multipleagent.git&apos;]]]) try &#123; echo &quot;---3in windows,start to unstash app---&quot; unstash &apos;app&apos; echo &quot;---3in windows,start to -B -Dmaven.test.failure.ignore verify---&quot; bat &apos;mvn -B -Dmaven.test.failure.ignore verify&apos; &#125; finally &#123; echo &quot;---3in windows,start to junit TEST-*.xml report---&quot; junit &apos;**/target/surefire-reports/TEST-*.xml&apos; &#125; &#125; &#125;&#125;","categories":[{"name":"Pipeline","slug":"Pipeline","permalink":"https://roclli.github.io/categories/Pipeline/"}],"tags":[{"name":"Jenkins Pipeline","slug":"Jenkins-Pipeline","permalink":"https://roclli.github.io/tags/Jenkins-Pipeline/"}]},{"title":"PP2-Demo-multipleagent-declartive","slug":"PP2-Demo-multipleagent-declartive","date":"2017-12-13T05:18:39.000Z","updated":"2017-12-13T06:36:07.234Z","comments":true,"path":"2017/12/13/PP2-Demo-multipleagent-declartive/","link":"","permalink":"https://roclli.github.io/2017/12/13/PP2-Demo-multipleagent-declartive/","excerpt":"","text":"Jenkins代码详见：https://gitee.com/roclli/9-multipleagent.git Jenkinsfile内容为：123456789101112131415161718192021222324252627282930313233343536373839404142434445464748pipeline &#123; agent none stages &#123; stage(&apos;Build&apos;) &#123; agent any steps &#123; checkout scm echo &apos;---going to execute---&apos; sh &apos;mvn -DskipTests clean package&apos; stash includes: &apos;**/target/*.jar&apos;, name: &apos;app&apos; &#125; &#125; stage(&apos;Test on Linux&apos;) &#123; agent &#123; label &apos;linux&apos; &#125; steps &#123; unstash &apos;app&apos; sh &apos;mvn test -Dtest=*Test || true&apos; &#125; post &#123; always &#123; junit &apos;**/target/surefire-reports/TEST-**.xml&apos; &#125; failure &#123; echo &apos;---on linux, there is some error---&apos; &#125; &#125; &#125; stage(&apos;Test on Windows&apos;) &#123; agent &#123; label &apos;windows&apos; &#125; steps &#123; unstash &apos;app&apos; bat &apos;mvn test -Dtest=*Test&apos; &#125; post &#123; always &#123; junit &apos;**/target/surefire-reports/TEST-**.xml&apos; &#125; failure &#123; echo &apos;---on windows, there is some error---&apos; &#125; &#125; &#125; &#125;&#125;","categories":[{"name":"Pipeline","slug":"Pipeline","permalink":"https://roclli.github.io/categories/Pipeline/"}],"tags":[{"name":"Jenkins Pipeline","slug":"Jenkins-Pipeline","permalink":"https://roclli.github.io/tags/Jenkins-Pipeline/"}]},{"title":"PP2-Demo-handingfailure-script","slug":"PP2-Demo-handingfailure-script","date":"2017-12-13T05:17:58.000Z","updated":"2017-12-13T06:36:03.610Z","comments":true,"path":"2017/12/13/PP2-Demo-handingfailure-script/","link":"","permalink":"https://roclli.github.io/2017/12/13/PP2-Demo-handingfailure-script/","excerpt":"","text":"1234567891011node &#123; stage(&apos;Test&apos;) &#123; try &#123; checkout([$class: &apos;GitSCM&apos;, branches: [[name: &apos;*/master&apos;]], doGenerateSubmoduleConfigurations: false, extensions: [], submoduleCfg: [], userRemoteConfigs: [[url: &apos;https://gitee.com/roclli/7-parameters-script.git&apos;]]]) sh &apos;mvn verify&apos; &#125; finally &#123; junit &apos;**/target/surefire-reports/TEST-**.xml&apos; &#125; &#125;&#125;","categories":[{"name":"Pipeline","slug":"Pipeline","permalink":"https://roclli.github.io/categories/Pipeline/"}],"tags":[{"name":"Jenkins Pipeline","slug":"Jenkins-Pipeline","permalink":"https://roclli.github.io/tags/Jenkins-Pipeline/"}]},{"title":"PP2-Demo-handingfailure-declarative","slug":"PP2-Demo-handingfailure-declarative","date":"2017-12-13T05:16:49.000Z","updated":"2017-12-13T06:35:59.970Z","comments":true,"path":"2017/12/13/PP2-Demo-handingfailure-declarative/","link":"","permalink":"https://roclli.github.io/2017/12/13/PP2-Demo-handingfailure-declarative/","excerpt":"","text":"Jenkins代码详见：https://gitee.com/roclli/7-parameters-script.git Jenkinsfile内容为：123456789101112131415161718192021222324252627pipeline &#123; agent any stages &#123; stage(&apos;Test&apos;) &#123; steps &#123; checkout scm //此处实际上执行了两次,第一次是界面指定了scm,本次又执行了一次 echo &apos;---going to execute---&apos; sh &apos;mvn verify&apos; &#125; &#125; &#125; post &#123; always &#123; echo &apos;---going to catch report---&apos; junit &apos;**/target/surefire-reports/TEST-**.xml&apos; &#125; failure &#123; echo &apos;---send mail start---&apos;// mail to: &apos;lijun11@metersbonwe.com&apos;, subject: &apos;The Pipeline(handing failure) failed :(&apos;, body: &apos;this is body&apos;// mail to: &apos;devops@acme.com&apos;, subject: &quot;Job &apos;$&#123;JOB_NAME&#125;&apos; ($&#123;BUILD_NUMBER&#125;) is waiting for input&quot;,// body: &quot;Please go to $&#123;BUILD_URL&#125; and verify the build&quot;// step([$class: &apos;Mailer&apos;, notifyEveryUnstableBuild: true, recipients: &quot;lijun11@metersbonwe.com&quot;, sendToIndividuals: true]) emailext body: &apos;this is body&apos;, subject: &apos;The Pipeline(handing failure) failed :(&apos;, to: &apos;lijun11@metersbonwe.com&apos; echo &apos;---send mail done---&apos; &#125; &#125;&#125;","categories":[{"name":"Pipeline","slug":"Pipeline","permalink":"https://roclli.github.io/categories/Pipeline/"}],"tags":[{"name":"Jenkins Pipeline","slug":"Jenkins-Pipeline","permalink":"https://roclli.github.io/tags/Jenkins-Pipeline/"}]},{"title":"PP2-Demo-parameters-script","slug":"PP2-Demo-parameters-script","date":"2017-12-13T05:16:14.000Z","updated":"2017-12-13T06:36:17.706Z","comments":true,"path":"2017/12/13/PP2-Demo-parameters-script/","link":"","permalink":"https://roclli.github.io/2017/12/13/PP2-Demo-parameters-script/","excerpt":"","text":"123456properties([parameters([string(defaultValue: &apos;Hello&apos;, description: &apos;How should I greet the world?&apos;, name: &apos;Greeting&apos;)])])node &#123; echo &quot;---will output params.Greeting&apos;s values:&quot; echo &quot;$&#123;params.Greeting&#125; World!&quot;&#125;","categories":[{"name":"Pipeline","slug":"Pipeline","permalink":"https://roclli.github.io/categories/Pipeline/"}],"tags":[{"name":"Jenkins Pipeline","slug":"Jenkins-Pipeline","permalink":"https://roclli.github.io/tags/Jenkins-Pipeline/"}]},{"title":"PP2-Demo-parameters-declarative","slug":"PP2-Demo-parameters-declarative","date":"2017-12-13T05:14:58.000Z","updated":"2017-12-13T06:37:48.252Z","comments":true,"path":"2017/12/13/PP2-Demo-parameters-declarative/","link":"","permalink":"https://roclli.github.io/2017/12/13/PP2-Demo-parameters-declarative/","excerpt":"","text":"Jenkins代码详见：https://gitee.com/roclli/7-parameters-script.git Jenkinsfile内容为：123456789101112131415161718192021222324252627pipeline &#123; agent any stages &#123; stage(&apos;Test&apos;) &#123; steps &#123; checkout scm //此处实际上执行了两次,第一次是界面指定了scm,本次又执行了一次 echo &apos;---going to execute---&apos; sh &apos;mvn verify&apos; &#125; &#125; &#125; post &#123; always &#123; echo &apos;---going to catch report---&apos; junit &apos;**/target/surefire-reports/TEST-**.xml&apos; &#125; failure &#123; echo &apos;---send mail start---&apos;// mail to: &apos;lijun11@metersbonwe.com&apos;, subject: &apos;The Pipeline(handing failure) failed :(&apos;, body: &apos;this is body&apos;// mail to: &apos;devops@acme.com&apos;, subject: &quot;Job &apos;$&#123;JOB_NAME&#125;&apos; ($&#123;BUILD_NUMBER&#125;) is waiting for input&quot;,// body: &quot;Please go to $&#123;BUILD_URL&#125; and verify the build&quot;// step([$class: &apos;Mailer&apos;, notifyEveryUnstableBuild: true, recipients: &quot;lijun11@metersbonwe.com&quot;, sendToIndividuals: true]) emailext body: &apos;this is body&apos;, subject: &apos;The Pipeline(handing failure) failed :(&apos;, to: &apos;lijun11@metersbonwe.com&apos; echo &apos;---send mail done---&apos; &#125; &#125;&#125;","categories":[{"name":"Pipeline Code","slug":"Pipeline-Code","permalink":"https://roclli.github.io/categories/Pipeline-Code/"}],"tags":[{"name":"Jenkins Pipeline","slug":"Jenkins-Pipeline","permalink":"https://roclli.github.io/tags/Jenkins-Pipeline/"}]},{"title":"PP2-Demo-setenv-script","slug":"PP2-Demo-setenv-script","date":"2017-12-13T05:14:25.000Z","updated":"2017-12-13T06:36:24.866Z","comments":true,"path":"2017/12/13/PP2-Demo-setenv-script/","link":"","permalink":"https://roclli.github.io/2017/12/13/PP2-Demo-setenv-script/","excerpt":"","text":"1234567891011121314node &#123; stage(&apos;set-env&apos;)&#123; echo &apos;going to git clone......&apos; git url: &apos;https://gitee.com/roclli/6-setting-env.git&apos; echo &quot;going to build..........&quot; echo &quot;---1:$&#123;tool &apos;M3&apos;&#125;---&quot; withEnv([&quot;PATH_MAVEN=$&#123;tool &apos;M3&apos;&#125;/bin&quot;])&#123; echo &quot;---2:$&#123;PATH_MAVEN&#125;---&quot; sh &quot;$&#123;PATH_MAVEN&#125;/mvn -B verify || true&quot; sh &quot;printenv&quot; &#125; &#125;&#125;","categories":[{"name":"Pipeline","slug":"Pipeline","permalink":"https://roclli.github.io/categories/Pipeline/"}],"tags":[{"name":"Jenkins Pipeline","slug":"Jenkins-Pipeline","permalink":"https://roclli.github.io/tags/Jenkins-Pipeline/"}]},{"title":"PP2-Demo-setenv-declarative","slug":"PP2-Demo-setenv-declarative","date":"2017-12-13T05:13:22.000Z","updated":"2017-12-13T06:36:21.066Z","comments":true,"path":"2017/12/13/PP2-Demo-setenv-declarative/","link":"","permalink":"https://roclli.github.io/2017/12/13/PP2-Demo-setenv-declarative/","excerpt":"","text":"Jenkins代码详见：https://gitee.com/roclli/6-setting-env.git Jenkinsfile内容为：123456789101112131415161718192021#!/usr/bing/env groovypipeline &#123; agent any environment &#123; CC = &apos;clang&apos; &#125; stages &#123; stage(&apos;Example&apos;)&#123; environment &#123; DEBUG = &apos;-g&apos; &#125; steps&#123; sh &apos;printenv&apos; &#125; &#125; &#125;&#125;","categories":[{"name":"Pipeline","slug":"Pipeline","permalink":"https://roclli.github.io/categories/Pipeline/"}],"tags":[{"name":"Jenkins Pipeline","slug":"Jenkins-Pipeline","permalink":"https://roclli.github.io/tags/Jenkins-Pipeline/"}]},{"title":"PP2-Demo-test-script","slug":"PP2-Demo-test-script","date":"2017-12-13T05:12:27.000Z","updated":"2017-12-13T06:36:33.577Z","comments":true,"path":"2017/12/13/PP2-Demo-test-script/","link":"","permalink":"https://roclli.github.io/2017/12/13/PP2-Demo-test-script/","excerpt":"","text":"12345678910111213141516171819202122232425262728293031323334353637383940node &#123;// try &#123; stage(&apos;Build&apos;)&#123; echo &apos;going to git clone......&apos; git url: &apos;https://gitee.com/roclli/5-build-tests.git&apos; echo &quot;going to build..........&quot; sh &quot;mvn -B -Dmaven.test.failure.ignore verify || true&quot; echo &quot;going to archiveArtifacts jar..........&quot; archiveArtifacts artifacts: &apos;**/target/**.jar&apos;, fingerprint: true &#125; stage(&apos;Test&apos;)&#123; // sh &apos;mvn clean install || true&apos; // sh &quot;mvn -B -Dmaven.test.failure.ignore verify&quot; echo &quot;junit testreport..........&quot; junit &apos;**/target/surefire-reports/TEST-**.xml&apos; &#125;// &#125; catch(e) &#123;// currentBuild.result = &quot;FAILURE&quot;// throw e// &#125; stage(&apos;Deploy&apos;)&#123; echo &quot;---env.BUILD_NUMBER is:$&#123;env.BUILD_NUMBER&#125;---&quot; echo &quot;---currentBuild.result is:$&#123;currentBuild.result&#125;---&quot; echo &quot;---env.BUILD_ID is:$&#123;env.BUILD_ID&#125;---&quot; echo &quot;---env.JOB_NAME is:$&#123;env.JOB_NAME&#125;---&quot; echo &quot;---env.JENKINS_URL is:$&#123;env.JENKINS_URL&#125;---&quot;// echo &quot;---&quot;$&#123;BUILD_NUMBER&#125;&quot;---&quot;// echo &quot;---1:&quot;currentBuild.result&quot;----2:$&#123;currentBuild.result&#125;---&quot;// //SUCCESS, UNSTABLE, or FAILURE (may be null for an ongoing build) if(currentBuild.result == null || currentBuild.result == &apos;SUCCESS&apos;) &#123; echo &quot;---currentBuild.result is:$&#123;currentBuild.result&#125;------&quot; &#125; else &#123; echo &quot;---currentBuild.result is:$&#123;currentBuild.result&#125;,so, will make publish&quot; &#125; &#125;&#125;","categories":[{"name":"Pipeline","slug":"Pipeline","permalink":"https://roclli.github.io/categories/Pipeline/"}],"tags":[{"name":"Jenkins Pipeline","slug":"Jenkins-Pipeline","permalink":"https://roclli.github.io/tags/Jenkins-Pipeline/"}]},{"title":"PP2-Demo-test-declarative","slug":"PP2-Demo-test-declarative","date":"2017-12-13T05:10:58.000Z","updated":"2017-12-13T06:36:30.277Z","comments":true,"path":"2017/12/13/PP2-Demo-test-declarative/","link":"","permalink":"https://roclli.github.io/2017/12/13/PP2-Demo-test-declarative/","excerpt":"","text":"Jenkins代码详见：https://gitee.com/roclli/5-build-tests.git Jenkinsfile内容为：1234567891011121314151617181920212223242526272829303132333435363738394041424344454647#!/usr/bing/env groovypipeline &#123; agent any //agent必需的,告诉Jenkins分配执行器和工作空间 stages &#123; //stage必需的, stage(&apos;Build&apos;) &#123; steps &#123; //step必需的 echo &apos;going to git clone......&apos; git url: &apos;https://gitee.com/roclli/5-build-tests.git&apos; echo &quot;going to build..........&quot; sh &quot;mvn -B -Dmaven.test.failure.ignore verify&quot; echo &quot;going to archiveArtifacts jar..........&quot; archiveArtifacts artifacts: &apos;**/target/**.jar&apos;, fingerprint: true &#125; &#125; stage(&apos;Test&apos;)&#123; steps&#123; // sh &apos;/mvn_home/bin/mvn clean install || true&apos; // sh &quot;/mvn_home/bin/mvn -B -Dmaven.test.failure.ignore verify&quot; echo &quot;junit testreport..........&quot; junit &apos;**/target/surefire-reports/TEST-**.xml&apos; &#125; &#125; stage(&apos;Deploy&apos;)&#123; steps &#123; script&#123; echo &quot;---$&#123;env.BUILD_NUMBER&#125;---&quot; echo &quot;---$&#123;currentBuild.result&#125;---&quot; echo &quot;---env.BUILD_ID is:$&#123;env.BUILD_ID&#125;---&quot; echo &quot;---env.JOB_NAME is:$&#123;env.JOB_NAME&#125;---&quot; echo &quot;---env.JENKINS_URL is:$&#123;env.JENKINS_URL&#125;---&quot; if(currentBuild.result == null || currentBuild.result == &quot;SUCCESS&quot;) &#123; echo &quot;---currentBuild.result is:$&#123;currentBuild.result&#125;------&quot; &#125; else &#123; echo &quot;---currentBuild.result is:$&#123;currentBuild.result&#125;,so, will make publish&quot; &#125; &#125; &#125; &#125; &#125;&#125;","categories":[{"name":"Pipeline","slug":"Pipeline","permalink":"https://roclli.github.io/categories/Pipeline/"}],"tags":[{"name":"Jenkins Pipeline","slug":"Jenkins-Pipeline","permalink":"https://roclli.github.io/tags/Jenkins-Pipeline/"}]},{"title":"PP2-Demo-build-script","slug":"PP2-Demo-build-script","date":"2017-12-13T05:09:50.000Z","updated":"2017-12-13T06:35:49.982Z","comments":true,"path":"2017/12/13/PP2-Demo-build-script/","link":"","permalink":"https://roclli.github.io/2017/12/13/PP2-Demo-build-script/","excerpt":"","text":"12345678910111213141516node &#123; stage(&apos;Build&apos;) &#123; echo &apos;Building....&apos; def username = &apos;Jenkins&apos; echo &apos;Hello Mr. $&#123;username&#125;&apos; echo &quot;I said, Hello Mr. $&#123;username&#125;&quot; checkout([$class: &apos;GitSCM&apos;, branches: [[name: &apos;*/master&apos;], [name: &apos;*/testbr&apos;]], doGenerateSubmoduleConfigurations: false, extensions: [], submoduleCfg: [], userRemoteConfigs: [[url: &apos;https://gitee.com/roclli/simple-maven-project-with-tests.git&apos;]]]) sh &quot;mvn -B -Dmaven.test.failure.ignore verify&quot; &#125; stage(&apos;Test&apos;) &#123; echo &apos;Testing....&apos; &#125; stage(&apos;Deploy&apos;) &#123; echo &apos;Deploying....&apos; &#125;&#125;","categories":[{"name":"Pipeline","slug":"Pipeline","permalink":"https://roclli.github.io/categories/Pipeline/"}],"tags":[{"name":"Jenkins Pipeline","slug":"Jenkins-Pipeline","permalink":"https://roclli.github.io/tags/Jenkins-Pipeline/"}]},{"title":"PP2-Demo-build-declarative","slug":"PP2-Demo-build-declarative","date":"2017-12-13T05:07:38.000Z","updated":"2017-12-13T06:35:46.563Z","comments":true,"path":"2017/12/13/PP2-Demo-build-declarative/","link":"","permalink":"https://roclli.github.io/2017/12/13/PP2-Demo-build-declarative/","excerpt":"","text":"Jenkins代码详见：https://gitee.com/roclli/4-declarative.git Jenkinsfile内容为：12345678910111213141516171819202122232425262728#!/usr/bing/env groovy//Declarativepipeline &#123; agent any //agent必需的,告诉Jenkins分配执行器和工作空间 stages &#123; //stage必需的, stage(&apos;Build&apos;) &#123; steps &#123; //step必需的 echo &apos;Building....&apos; checkout([$class: &apos;GitSCM&apos;, branches: [[name: &apos;*/master&apos;]], doGenerateSubmoduleConfigurations: false, extensions: [], submoduleCfg: [], userRemoteConfigs: [[url: &apos;https://gitee.com/roclli/4-declarative.git&apos;]]])\\// def username = &apos;Jenkins&apos;// echo &apos;Hello Mr. $&#123;username&#125;&apos;// echo &quot;I said, Hello Mr. $&#123;username&#125;&quot; &#125; &#125; stage(&apos;Test&apos;) &#123; steps&#123; echo &apos;Testing....&apos; &#125; &#125; stage(&apos;Deploy&apos;) &#123; steps&#123; echo &apos;Deploying....&apos; &#125; &#125; &#125;&#125;","categories":[{"name":"Pipeline","slug":"Pipeline","permalink":"https://roclli.github.io/categories/Pipeline/"}],"tags":[{"name":"Jenkins Pipeline","slug":"Jenkins-Pipeline","permalink":"https://roclli.github.io/tags/Jenkins-Pipeline/"}]},{"title":"Pipeline2-Demo-checkoutscm","slug":"PP2-Demo-checkoutscm","date":"2017-12-13T05:04:30.000Z","updated":"2017-12-13T06:35:53.666Z","comments":true,"path":"2017/12/13/PP2-Demo-checkoutscm/","link":"","permalink":"https://roclli.github.io/2017/12/13/PP2-Demo-checkoutscm/","excerpt":"","text":"Jenkins代码详见：https://gitee.com/roclli/simple-maven-project-with-tests.git Jenkinsfile内容为：12345678910111213141516171819202122232425262728#!/usr/bing/env groovynode(&apos;master&apos;) &#123; echo &quot;----------------------start git url----------------------&quot; checkout scm echo &quot;----------------------version()----------------------&quot; def v = version() if (v) &#123; echo &quot;---Building version $&#123;v&#125;---&quot; &#125; def mvnHome = tool &apos;M3&apos; echo &quot;----------------------mvn -B -D verify----------------------&quot; sh &quot;$&#123;mvnHome&#125;/bin/mvn -B -Dmaven.test.failure.ignore verify&quot;&#125;def version() &#123; def matcher = readFile(&apos;pom.xml&apos;) =~ &apos;&lt;version&gt;(.+)&lt;/version&gt;&apos; echo &quot;---$&#123;matcher[0][1]&#125;---&quot; //---1.0-SNAPSHOT--- echo &quot;---$&#123;matcher[0][2]&#125;---&quot; //---null--- echo &quot;---$&#123;matcher[0][3]&#125;---&quot; //---null--- echo &quot;---$&#123;matcher[1][1]&#125;---&quot; //---2.18.1--- echo &quot;---$&#123;matcher[1][2]&#125;---&quot; //---null--- echo &quot;---$&#123;matcher[1][3]&#125;---&quot; //---null--- echo &quot;---$&#123;matcher[2][1]&#125;---&quot; //---4.11--- echo &quot;---$&#123;matcher[2][2]&#125;---&quot; //---null--- echo &quot;---$&#123;matcher[2][3]&#125;---&quot; //---null--- matcher ? matcher[0][1] : null&#125;","categories":[{"name":"Pipeline","slug":"Pipeline","permalink":"https://roclli.github.io/categories/Pipeline/"}],"tags":[{"name":"Jenkins Pipeline","slug":"Jenkins-Pipeline","permalink":"https://roclli.github.io/tags/Jenkins-Pipeline/"}]},{"title":"Pipeline1-Demo-Helloworld","slug":"PP1-Demo-Helloworld","date":"2017-12-13T05:03:07.000Z","updated":"2017-12-13T06:38:10.095Z","comments":true,"path":"2017/12/13/PP1-Demo-Helloworld/","link":"","permalink":"https://roclli.github.io/2017/12/13/PP1-Demo-Helloworld/","excerpt":"","text":"1234node &#123; echo &quot;Hello World!!!&quot; echo &apos;Hello World!!!&apos;&#125;","categories":[{"name":"Pipeline Code","slug":"Pipeline-Code","permalink":"https://roclli.github.io/categories/Pipeline-Code/"}],"tags":[{"name":"Jenkins Pipeline","slug":"Jenkins-Pipeline","permalink":"https://roclli.github.io/tags/Jenkins-Pipeline/"}]},{"title":"(原创)Pipeline7-Pipeline-Syntax","slug":"Pipeline7-Pipeline-Syntax","date":"2017-12-13T02:09:15.000Z","updated":"2017-12-13T06:35:36.003Z","comments":true,"path":"2017/12/13/Pipeline7-Pipeline-Syntax/","link":"","permalink":"https://roclli.github.io/2017/12/13/Pipeline7-Pipeline-Syntax/","excerpt":"","text":"笔者是独立翻译实验，不允许转载 Pipeline Syntax本节基于入门中介绍的信息, 应仅作为参考进行处理。有关如何在实际示例中使用Pipeline语法的详细信息, 请参阅本章的 Jenkinsfile 部分。在Pipeline插件的2.5 版中, Pipeline支持两个离散的语法, 下面是详细的。对于每个优点和缺点, 请参见语法比较。 正如在入门中所讨论的, Pipeline最基本的部分是步骤step。基本上, 步骤step告诉Jenkins该做什么, 并作为声明式和脚本式Pipeline语法的基本构造块。 有关可用步骤的概述, 请参阅Pipeline步骤参考, 其中包含内置的步骤的全面列表以及插件提供的步骤。 Declarative Pipeline声明式Pipeline是Jenkins Pipeline的一个相对最近的加法, 它在Pipeline子系统的顶部提供了一种更简化和自以为是的语法。 所有有效的声明Pipeline必须包含在Pipeline块中, 例如: 在声明性Pipeline中有效的基本语句和表达式遵循与 Groovy 语法相同的规则, 但有以下例外情况: Pipeline的 top-level 必须是一个块, 特别是: pipeline {} 没有分号作为语句分隔符。每个语句都必须在自己的行上 块必须由节、指令、步骤或赋值语句组成。 属性引用语句被视为参数方法调用。例如, 输入被视为输入 () Sections声明性Pipeline中的节通常包含一个或多个指令Directive或步骤steps。 agent代理部分指定在Jenkins环境中执行整个Pipeline或特定阶段的位置, 具体取决于代理部分的放置位置。该节必须在Pipeline块内的 top-level 中定义, 但阶段级别的时候使用是可选的。 RequiredYesParametersDescribed belowAllowedIn the top-level pipeline block and each stage block Parameters为了支持Pipeline作者可能有的各种用例, 代理部分支持几种不同类型的参数。这些参数可在Pipeline块的 top-level 或每个阶段指令中应用。 any在任何可用的代理上执行Pipeline或阶段。例如: 代理任何agent any。 none当在Pipeline块的 top-level 应用时, 将不会为整个Pipeline运行分配全局代理, 并且每个阶段部分都需要包含其自己的代理部分。例如: 代理无agent none。 label使用所提供的标签, 在Jenkins环境中可用的代理上执行Pipeline或stage。例如: 代理 {标签为‘my-defined-label’}。 nodeagent{ node {label ‘labelName’}}}和agent { label ‘labelName’}一样，node允许附加的选项，例如customWorkspace。 docker对给定的容器执行Pipeline或stage, 在预先配置为接受 Docker-based Pipeline的节点上或在与可选的标签参数匹配的节点上动态调配。Docker还可以选择接受参数, 其中可能包含直接传递到docker运行调用的参数, 以及一个 alwaysPull 选项, 即使图像名称已存在, 也会强制执行docker。例如 agent { docker ‘maven：3-alpine’} dockerfile使用源存储库中包含的Dockerfile生成的容器来执行Pipeline或stage。要想使用这个选项，Jenkinsfile必须通过Multibranch Pipeline或者Pipeline from SCM。通常这是源存储库根目录中的 Dockerfile：agent { dockerfile true }。如果在另一个目录中生成Dockerfile, 请使用dir选项：agent { dockerfile { dir ‘somSubDir’} }。您可以用additionalBuildArgs选项传递参数到docker build……命令中，像agent { dockerfile { additionalBuildArgs ‘–build-arg foo=bar’ } }。 Common Options这些是可以应用两个或更多agent实现的几个选项。除非明确说明, 否则不是必需的。 Label一个字符串。要在其上运行Pipeline或单个stage的标签。此选项对于node，docker和dockerfile有效，并且对node是必需的。 customWorkspace一个字符串。运行Pipeline或单个stage，此agent在该自定义工作区中应用, 而不是默认。它可以是相对路径, 在这种情况下, 自定义工作区将位于节点的工作区根目录下, 或者是绝对路径。例如： 此选项对于node，docker和dockerfile有效。 reuseNode布尔值, 默认为 false。如果为 true, 则在Pipeline的 top-level 上指定的节点上, 在同一工作区中, 而不是在新节点上运行容器。 此选项对docker和dockerfile有效, 并且仅在用于单个stage的agent时具有效果。 Example ①在新创建的给定名称和标记(maven:3-alpine)容器中, 执行此Pipeline中定义的所有步骤。 Stage-level agent部分 在Pipeline的 top-level 定义agent none, 确保不会不必要地分配执行器。使用agent none 还强制每个stage部分包含其自己的agent部分。 使用此image在新创建的容器中执行此阶段中的步骤。 使用上一个阶段的不同image, 在新创建的容器中执行此阶段中的步骤。 Postpost 部分定义将在Pipeline运行或阶段结束时运行的操作。post 部分中支持许多条件块: 始终(always)、已更改(changed)、失败(failure)、成功(success)、不稳定(unstable)和中止(aborted)。这些块允许在Pipeline运行或阶段的末尾执行步骤, 具体取决于管线的状态。 RequiredNo ParametersNoneAllowedIn the top-level pipeline block and each stage block Conditionsalways 无论Pipeline运行的完成状态如何, 都将运行。 changed 仅当当前Pipeline运行与以前完成的Pipeline的状态不同时才运行。 failure 只有在当前Pipeline出现故障状态时才运行, 通常在 web UI 中用红色指示表示。 success 只有在当前Pipeline具有成功状态时才运行, 通常在 web UI 中用蓝色或绿色表示。 unstable 只有在当前Pipeline的状态不稳定时才运行, 通常是由测试失败、代码违规等引起的。通常用黄色指示在 web UI 中表示。 aborted 仅在当前Pipeline具有中止状态时运行, 通常是由于Pipeline被手动中止。通常在 web UI 中用灰色指示表示。 Example 通常情况下, post部分应放置在Pipeline的末尾。 Post-condition块包含与steps部分相同的steps。 stages包含一个或多个stage指令的序列, stages部分是Pipeline所描述的大部分”work”的位置。至少建议stages对连续传递过程中的每个离散部分 ，如生成、测试和部署， 至少包含一个阶段指令。 RequiredYesParametersNoneAllowedOnly once, inside the pipeline block Example stage部分通常遵循指令, 如代理agent、选项options等。 stepssteps部分在指定的stage指令中定义一系列一个或多个将要执行的steps。 RequiredYesParametersNoneAllowedinside each stage block Example steps部分包含一个或多个steps。 Directivesenvironment环境environment指令指定一个键值对序列, 它将被定义为所有steps的环境变量, 或特定阶段的steps, 具体取决于环境environment指令在Pipeline中的位置。 此指令支持一种特殊的方法credentials(), 可用于通过Jenkins环境中的标识符来访问预定义的凭据。对于类型为机密文本的凭据, credentials()方法将确保指定的环境变量包含秘密文本内容。对于类型为标准用户名和密码的凭据, 指定的环境变量将被设置为用户名: 密码和另外两个环境变量将被自动定义：MYVARNAME_USR和MYVARNAME_PSW。 RequiredNoParametersNoneAllowedinside the pipeline block, or within stage directives Example top-level Pipeline块中使用的environment指令将应用于Pipeline中的所有步骤。 在stage中定义的environment指令只将给定的环境变量应用于stage中的步骤。 environment块具有定义的帮助方法credentials() 可用于通过Jenkins环境中的标识符来访问预定义的凭据。 Optionsoptions指令允许在管线本身内配置Pipeline特定的选项。Pipeline提供了许多这些选项, 如buildDiscarder, 但它们也可能由插件提供, 如时间戳timestamps。RequiredNoParametersNoneAllowedOnly Once, inside the pipeline block#### Available Options###### buildDiscarder持久性工件(Persist artifacts)和控制台输出的特定数量的最近Pipeline运行。例如：options { buildDiscarder(logRotator(numToKeepStr: ‘1’)) }。###### disableConcurrentBuilds不允许并发执行Pipeline。可用于防止同时访问共享资源等。例如：options { disableConcurrentBuilds() }。###### overrideIndexTriggers允许重写分支索引触发器的默认处理。如果在 multibranch 或组织标签中禁用了分支索引触发器, 则options {overrideIndexTriggers (true)}将仅为该作业启用它们。否则,options {overrideIndexTriggers (false)}将仅禁用此作业的分支索引触发器。###### skipDefaultCheckout在agent指令中, 在默认情况下跳过源代码管理中的签出。例如: options {skipDefaultCheckout ()}。###### skipStageAfterUnstable一旦生成状态不稳定, 就跳过各个阶段。例如: options {skipStagesAfterUnstable ()}。###### timeout设置Pipeline运行的超时期限, 之后Jenkins应中止Pipeline。例如: options { timeout(time: 1, unit: ‘HOURS’) }。###### retry失败时, 请在指定的次数内重试整个管线。例如: options { retry(3) }。###### timestamps将管线所生成的所有控制台输出与发出该行的时间放在一起。例如: options { timestamps() }。###### Examples* 指定一个小时的全局执行超时, 之后Jenkins将中止Pipeline运行。提示：可供选择的综合清单尚待INFRA-1503完成。#### parameters参数parameters指令提供用户在触发Pipeline时应提供的参数列表。这些用户指定的参数的值可通过参数params对象提供给Pipeline steps, 请参阅]示例中的特定用法。RequiredNoParametersNoneAllowedOnly Once, inside the pipeline block#### Available Parameters###### string字符串类型参数，例如：parameters { string(name: ‘DEPLOY_ENV’, defaultValue: ‘staging’, description: ‘’) } booleanParam布尔值参数，例如：parameters { booleanParam(name: ‘DEBUG_BUILD’, defaultValue: true, description: ‘’) } Examples 提示：可供选择的综合清单尚待INFRA-1503完成。 Triggerstriggers指令定义了Pipeline应 re-triggered 的自动方式。对于与源 (如 GitHub 或 BitBucket) 集成的管线, 可能不需要triggers, 因为 webhooks-based 集成可能已经存在。当前可用的触发器有 cron、pollSCM 和upstream。 RequiredNoParametersNoneAllowedOnly Once, inside the pipeline block Cron接受一个 cron 样式的字符串来定义Pipeline应 re-triggered 的规则间隔。例如：triggers { cron(‘H */4 1-5’) }。 pollSCM接受一个 cron 样式的字符串来定义一个规则的时间间隔, 詹金斯应该检查新的源更改。例如：triggers { pollSCM(‘H */4 1-5’) }。 upstream接受一个逗号分隔的作业字符串和一个阈值。当字符串中的任何作业以最小阈值结束时, 管线将被 re-triggered。例如：triggers { upstream(upstreamProjects: ‘job1,job2’, threshold: hudson.model.Result.SUCCESS) }。提示：pollSCM触发器只在Jenkins版本2.22或者以后有效。。 Example stagestage指令进入stages部分，应该包含一个steps部分，一个可选的agent部分，或者其它特殊平台指令。实际上, Pipeline所完成的所有工作都将在一个或多个stage指令中进行包装。 RequiredAt least oneParametersOne mandatory parameter, a string for the name of the stage.AllowedInside the stages section Example tools定义用于自动和放置PATH的工具的部分。如果agent none指定, 则忽略此项。 RequiredNoParametersNoneAllowedInside the pipeline block or a stage block. Supported ToolsmavenjdkgradleExample 工具名称必须在Jenkins中预先配置：Manage Jenkins → Global Tool Configuration。 whenwhen指令允许Pipeline根据给定的条件来决定是否执行stage。when指令必须包含至少一个条件。如果when指令包含多个条件时, 所有子条件必须返回 true 才能执行阶段。这与子条件嵌套在allof条件下的情况相同 (请参见下面的示例)。 可以使用嵌套条件构建更复杂的条件结构: not、allOf或anyOf。嵌套条件可以嵌套到任意深度。 RequiredNoParametersNoneAllowedInside a stage directive Built-in Conditionsbranch在所构建的分支与给定的分支模式匹配时执行stage，例如：when { branch ‘master’ }。注意：这仅仅在multibranch Pipeline有效。 environment特殊环境变量被设置给定值以后，执行stage，例如：when { environment name: ‘DEPLOY_TO’, value: ‘production’ }。 expression当指定的Groovy表达式计算为真时执行stage，例如：when { expression { return params.DEBUG_BUILD } }。 not当嵌套条件为假时执行stage。例如：when { not { branch ‘master’ } }。 allOf当所有嵌套条件为真时执行stage。必须包含至少一个条件，例如：when { allOf { branch ‘master’; environment name: ‘DEPLOY_TO’, value: ‘production’ } }。 anyOf当至少一个前条件为真时执行stage。必须包含至少一个条件，例如：when { anyOf { branch ‘master’; branch ‘staging’ } }。 Examples Parallel申明式Pipeline中有可能在里面申明许多嵌套的stages，这些stage将被并行执行。请注意, 一个stage必须有一个且只有一个steps或parallel。嵌套stage本身不能包含进一步的parallel stages, 但其他的行为与其他stages相同。包含parallel的任何stage都不能包含agent或tools, 因为没有steps，他们并不具有相关性。 此外, 您可以强制您的parallel stage全部被中止, 当其中一个失败, 通过增加’failFast true’到包含parallel的stage。 Example Steps声明式Pipeline可能会使用Pipeline steps reference中记录的所有可用steps, 其中包含一个完整的steps列表, 其中添加了仅在声明性Pipeline中支持的下面列出的steps。 scriptscript step采用了一个脚本化的Pipeline块, 并在声明性Pipeline中执行。对于大多数用例, 脚本步骤在声明性Pipeline中应该是不必要的, 但它可以提供一个有用的”escape hatch”。 Script块和/或复杂性的脚本script块应该改为]共享库。 Example Scripted Pipeline脚本化Pipeline (如声明式Pipeline) 建立在底层管线子系统的顶部。不像声明式, 脚本Pipeline是有效的通用 DSL 内置的 Groovy。Groovy 语言提供的大多数功能都可供脚本Pipeline用户使用, 这意味着它可以是一个非常富有表现力和灵活性的工具, 可以创作连续的交付Pipeline。 Flow Control脚本化Pipeline从 Jenkinsfile 的顶部向下连续执行, 就像 Groovy 或其他语言中的大多数传统脚本一样。因此, 提供流控制依赖于 Groovy 表达式, 如 if/else 条件, 例如: 通过 Groovy 的异常处理支持, 可以管理另一种脚本式Pipeline流控制。当steps因任何原因而失败时, 它们抛出一个异常。错误处理行为必须使用 Groovy 中的 try/catch/finally 块, 例如: Steps正如在入门中所讨论的, Pipeline最基本的部分是”step”。从根本上讲, step告诉Jenkins该做什么, 并充当声明性和脚本化Pipeline语法的基本构建基块。脚本Pipeline不引入特定于其语法的任何steps; Pipeline Steps reference, 其中包含Pipeline和插件提供的steps的全面列表。 Differences from plain Groovy为了提供耐用性, 这意味着运行Pipeline可以生存的Jenkins master重启, 脚本Pipeline必须序列化数据回master。由于这一设计要求, 一些 Groovy 成语如collection.each { item -&gt; /* perform operation */ }不完全受支持。有关详细信息, 请参阅 JENKINS-27421 和 JENKINS-26481。 Syntax Comparison当Jenkins Pipeline首次创建时, Groovy 被选为基础。Jenkins长期推出了一个嵌入式的 Groovy 引擎, 为管理员和用户提供高级脚本功能。此外, Jenkins Pipeline的实现基于 Groovy 的基础上, 建立现在称为”脚本Pipeline” DSL。 由于它是一个功能完备的编程环境, 因此脚本化的管道为Jenkins用户提供了大量的灵活性和可扩展性。对于给定团队的所有成员来说, Groovy 学习曲线通常并不可取, 因此创建了声明性Pipeline, 为创作Jenkins Pipeline提供了更简单、更可用的语法。 两者基本上是相同的Pipeline子系统下面。它们都是作为”代码即管道(Pipeline as code)”的持久实现。他们都能够使用Pipeline内置的steps或由插件提供。都可以利用共享库。 然而他们不同的地方在句法和灵活性。声明性限制用户使用更严格和预先定义的结构, 使其成为更简单的连续传递Pipeline的理想选择。脚本提供的限制很少, 因为结构和语法的唯一限制往往是由 Groovy 本身定义的, 而不是任何特定于Pipeline的系统, 这使得它成为了电力用户和更复杂需求的理想选择。顾名思义, 声明性Pipeline是鼓励一个声明式编程模型。而脚本化的Pipeline遵循更命令性的编程模型。","categories":[{"name":"Pipeline","slug":"Pipeline","permalink":"https://roclli.github.io/categories/Pipeline/"}],"tags":[{"name":"Jenkins Pipeline","slug":"Jenkins-Pipeline","permalink":"https://roclli.github.io/tags/Jenkins-Pipeline/"}]},{"title":"(原创)Pipeline6-Pipeline-Development-Tools","slug":"Pipeline6-Pipeline-Development-Tools","date":"2017-12-13T01:58:11.000Z","updated":"2017-12-13T06:35:31.567Z","comments":true,"path":"2017/12/13/Pipeline6-Pipeline-Development-Tools/","link":"","permalink":"https://roclli.github.io/2017/12/13/Pipeline6-Pipeline-Development-Tools/","excerpt":"","text":"笔者是独立翻译实验，不允许转载 Pipeline Development ToolsPipeline Development ToolsJenkins Pipeline有内嵌的文档和Snipper Generator，这些是开发Pipeline的关键资源。它们针对当前版本的Jenkins和安装的插件提供详细的帮助和信息。本节，我们讨论开发Jenkins Pipeline的其他工具和资源。 命令行Command-line (Command-line Pipeline Linter)在实际运行之前，Jenkins能验证，或者lint一个申明式Pipeline。这些通常是Jenkins CLI命令或者带参数的HTTP POST请求完成的。我们推荐使用SSH interface。请参看Jenkins CLI文档怎样配置Jenkins才能安全的命令行存取。 Example下面是两个Pipeline Linter的例子。第一个示例显示了linter在传递无效Jenkinsfile时的输出, 该结果是缺少代理agent声明的一部分。 “Replay” Pipeline Runs with Modifications一般来说Pipeline是定义在经典的Jenkins Web界面上，或者通过提交Jenkinsfile到源代码库中。不幸的是, 这两种方法都不适合对Pipeline进行快速迭代或原型化。“Replay”特性允许在不更改Pipeline配置或创建新提交的情况下快速修改和执行现有Pipeline。 Usage使用”Replay”特性: 选择一个以前已经完成的运行过的Build History。 点击左边的菜单”Replay”按钮 Features•能被同一次运行多次调用—允许很容易的并行测试不同的特性•能被在运行中的Pipeline调用执行—只要是包含正确Groovy语法的Pipeline，就能被重复播放。•能引用共享库的代码同样是可修改的—如果一个引用了共享库的Pipeline运行，共享库的代码同样能被展示和修改。 Limitations•有语法错误的Pipeline不能被重新播放–这意味着无法查看其代码, 并且无法检索其中所做的任何更改。使用重播进行更重要的修改时, 请将更改保存到Jenkins外部的文件或编辑器中, 然后再运行它们。见JENKINS-37589。 •重播的Pipeline行为可能与由其他方法启动的运行不同–对于不属于多分支Pipeline的Pipeline, 提交信息可能会因原始运行和重播运行而异。见JENKINS-36453。 Pipeline Unit Testing Framework提示: Pipeline单元测试框架是Jenkins项目不支持的 third-party 工具。Pipeline单元测试框架（Pipeline Unit Testing Framework）允许您在完全运行测试Pipeline和共享库之前对其进行单元检测。它提供了一个模拟执行环境, 其中实际的Pipeline步骤将替换为可用于检查预期行为的 mock 对象。新的和粗糙的边缘, 但承诺。该项目的自述文件包含示例和用法说明。","categories":[{"name":"Pipeline","slug":"Pipeline","permalink":"https://roclli.github.io/categories/Pipeline/"}],"tags":[{"name":"Jenkins Pipeline","slug":"Jenkins-Pipeline","permalink":"https://roclli.github.io/tags/Jenkins-Pipeline/"}]},{"title":"(原创)Pipeline5-Extending-with-Shared-Libraries","slug":"Pipeline5-Extending-with-Shared-Libraries","date":"2017-12-13T01:13:10.000Z","updated":"2017-12-13T06:35:28.379Z","comments":true,"path":"2017/12/13/Pipeline5-Extending-with-Shared-Libraries/","link":"","permalink":"https://roclli.github.io/2017/12/13/Pipeline5-Extending-with-Shared-Libraries/","excerpt":"","text":"笔者是独立翻译实验，不允许转载 Extending with Shared LibrariesDefining Shared LibrariesPipeline被越来越多的组织和项目所使用，一些常用的模式开始出现。通常共享不同项目的Pipeline片段是非常有用的，能减少冗余，保持代码DRY(Don’t_repeat_yourself)。 Pipeline支持创建共享库，这些库能被外部源代码库定义，并能被装载到现有的Pipeline中。 Directory structure共享库被一个名字，一个例如SCM的代码段定义，默认的版本是可选的。名字是一个短标识符，它能被用在脚本中。 版本可以是SCM能理解的任何东西；例如分支，标记和提交hashes等所有Git的东西你同样可以申明哪些脚本明确要求下面定义的库，或者默认是禁止的。更进一步，如果你在Jenkins配置中说明一个版本，你就能阻止脚本选择一个不同的版本。 说明SCM最好的方式就是使用SCM插件，插件已经被更新支持新的API，检查任意的命名版本。最新版本的Git和Subversion插件都支持这个模式；其他也应该这么做。 如果你的SCM插件没有被整合，你可以选择Legacy SCM，并且挑选已经提供的。在本例中，你需要在SCM配置的某个地方包含(include)${library.yourLibName.version}，以便于在迁出代码阶段，插件能读取这个变量选择想要的版本。例如，对于Subversion，你能设置URI为svnserver/project/${library.yourLibName.version}，然后使用例如trunk或者branches/dev或者tags/1.0。 目录结构(Directory structure)共享库的目录结构如下： src目录看起来像是标准的java代码目录。当执行Pipeline的时候，这个目录会被加到classpath。 vars目录保存脚本，脚本定义Pipeline可以存取的全局变量。每一个groovy的基本名应该是一个Groovy标识符，方便起见都是驼峰命名法。 这些目录中的Groovy原文件都与脚本Pipeline同样的”CPS transformation”。 resources目录允许libraryResource被外部库使用加载非Groovy文件。现在这个特性不支持内部库。 Global Shared Libraries有好几个可以定义共享库的地方，取决于用户情况。Manage Jenkins » Configure System » Global Pipeline Libraries，在这里许多库都能被定义。 因为这些库是全局使用，系统中的任何Pipeline都可以用这些库中的功能。这些库被认为是”可信任的”，他们能运行Java/Geoovy/Jenkins内部API/Jenkins插件或者第三方库的任何方法。这允许你以一个更高级别封装去包裹独立的不安全的APIs，供其他Pipeline使用。要知道，任何能提交文件到这个SCM库的人都能对Jenkins进行无限的存取。你需要全部/运行权限去配置库(通常权限被授予jenkins管理员)。 Folder-level Shared Libraries任何创建的目录都可以有和它相关联的共享库。这个机制允许特殊库对目录和子目录中的Pipeline作用范围。目录为基础的库并不被认为是”可信任的”；它们在Groovy sandbox中的运行就像典型的Pipeline一样。 Automatic Shared libraries其他插件可以增加定义库的方法。例如插件github-branch-source提供一个GitHub组织目录项，这个目录项允许脚本不用任何附加配置就可以使用不受信任的库，例如github.com/someorg/somerepo。本例中，指定的GitHub库将被加载。 Using libraries隐式加载的共享库允许Pipeline使用任意这样的库定义的类或者全局变量。存取其他的库，Jenkinsfile需要使用@Library标记，说明库的名字： 这些标记可以在Groovy脚本允许的任何地方。当引用类库(src目录)的时候，相应标记需要一个import表达式： 提示：对于只定义了全局变量的共享库，或者只需要一个全局变量的共享库，&lt;a href=&quot;http://groovy-lang.org/objectorientation.html#&lt;em&gt;annotation&quot;&gt;annotation&lt;/a&gt; pattern &lt;code&gt;@Library(&#39;my-shared-library&#39;) _&lt;/code&gt;保持代码精炼是有用的。本质上，替代标记一个不必要的import表达式，符号被标记。 不推荐import一个全局变量/函数，因为这将强迫编译器将字段和方法解释为静态(static)的。此种情况下的Groovy编译器会产生令人迷惑的错误信息。在脚本的编译过程中, 库在开始执行之前被解析和加载。这使得 Groovy 编译器能够理解静态类型检查中使用的符号的含义, 并允许它们在脚本中的类型声明中使用, 例如 但是, 全局变量在运行时解析。 Loading libraries dynamically从Pipeline2.7 版: 共享的 Groovy 库插件中, 有一个新的选项用于在脚本中加载 (non-implicit) 库: 在生成过程中的任何时候动态加载库的一个library步骤。 如果你只对使用全局变脸函数感兴趣(从vars目录)，语法是相当的简单： 此后, 脚本将可以访问该库中的任何全局变量。也可以使用src/目录中的类, 但更棘手。虽然 @Library 注释在编译之前已经准备脚本的classpath, 但在遇到library step时, 脚本已经编译完毕。因此, 您无法从库中import或以其他方式，静态引用类型。但是, 您可以动态地使用库类 (没有类型检查), 通过完全访问来自library step的返回值的限定名。可以使用类似于 Java 的语法调用静态static方法: 您还可以访问静态字段, 并调用构造函数, 就好像它们是名为new的静态方法一样： Library versions当隐式加载被选中的时候，共享库使用默认版本，否则pipeline只通过名字引用库，例如@Library(‘my-shared-library’)。如果默认版本没有定义，Pipeline必须说明一个版本，例如@Library(‘my-shared-library@master’)。 如果共享库配置中的”允许默认版本被覆盖”被选中，@Library标记有可能覆盖库的默认版本。如果可能的话，这同样允许隐式加载的库能被加载不同的版本。 当时使用library step，你可以说明一个版本： 由于这是一个常规步骤(library step), 因此可以计算该版本而不是常量, 就像注释；例如： 将使用与 multibranch Jenkinsfile 相同的 SCM 分支加载库。另外一个例子中，你可以通过参数选择一个库： 注意：Library step可能不可以被用来覆盖一个隐式加载库的版本。它在脚本开始的时候已经加载，并且一个用名字加载的库不能被加载两次。 Retrieval Method说明SCM最好的方式是使用SCM插件，插件已经被更新支持新的API去检查版本。在写本文时，Git和Subversion插件已经支持这个模式。 Legacy SCMSCM插件有可能仍然通过Legacy SCM选项使用，因为插件还没有支持交心的共享库特性。本例中，包含${library.yourlibrarynamehere.version}，在这里分支/tag/ref为了特殊的SCM插件被配置。这确保，在迁出库的源代码时，SCM插件能扩展它的变量去迁出合适的库版本。 Dynamic retrieval如果你在Library step中仅仅指明一个库名字(可选的，在version后面@) ，Jenkins将寻找那个名字的预先配置的库。(或者加载一个github.com/owner/repo自动库)但您也可以动态地指定检索方法, 在这种情况下, 不需要在Jenkins中预先定义库。例子如下： 最好使用Pipeline Syntax寻找你的SCM的精确的语法。注意：在这些cases中，必须要说明库版本。 Writing libraries一般来说，任何合法的Groovy代码都可以使用。不同的数据结构，功能方法等，例如： Access steps库的类不能明确的调用steps，例如sh或者git。但是, 它们可以在封闭类的范围之外实现方法, 进而调用Pipeline step，例如： 然后这个方法可以被脚本式Pipeline调用。 这个方法是有限制的，例如，它阻止一个父类的定义。或者，在构造函数中，一套steps集合能用this被明确的传递到一个库类，或者仅仅一个方法： 当保存类的状态的时候，例如上面，类必须实现Serializable接口。 这确保在Jenkins中，一个使用类的Pipeline，像下面的例子，能挂起(suspend)和回复(resume)。 如果库需要存取全局变量，例如env，那么这些库应该被明确的传递到库类，或者方法中。而不是将大量的变量从脚本式Pipeline传递到库中, 上面的例子展示了参数被传递到一个静态(static)方法，脚本式Pipeline按照如下方式调用： Defining global variables在内部,vars目录中的脚本按要求实例化为单例。这允许在单个. groovy 文件中定义多个方法以方便使用。 声明式Pipeline不允许在脚本指令之外使用全局变量用法 (JENKINS-42360)。 ① script在声明式Pipeline中访问全局变量所需的脚本指令。注意：在Jenkins加载并使用该库作为成功的Pipeline运行的一部分之后, 在共享库中定义的变量将只显示在全局变量引用 (在Pipeline Syntax中)。警告：避免在全局变量中保留状态避免使用交互或保留状态的方法来定义全局变量。改用静态类或实例化类的局部变量。 Defining custom steps共享库还可以定义与内置步骤 (如 sh 或 gitgit) 类似的全局变量。在共享库中定义的全局变量必须用所有 lower-case 或法则命名, 以便通过管道正确加载。 例如, 要定义 sayHello, 应创建文件 vars/sayHello.groovy, 并应实现调用方法。调用方法允许以类似于步骤的方式调用全局变量: Pipeline能引用和调用这个变量： 如果用块调用, 则调用方法将接收关闭。应显式定义该类型以阐明步骤的意图, 例如: 然后, Pipeline可以像任何接受块的内置步骤一样使用此变量: Defining a more structured DSL如果您有很多类似的管道, 则全局变量机制提供了一个方便的工具来构建一个 higher-level 的 DSL 来捕获相似性。例如, 所有的詹金斯插件都是以同样的方式构建和测试的, 所以我们可以写一个名为buildPlugin的step。 假设脚本已作为全局共享库或文件夹级共享库加载, 结果 Jenkinsfile 将大大简化： Using third-party libraries可以使用 third-party 的 Java 库, 通常是在 Maven 中心, 从受信任的库代码使用@Grab注释。有关细节, 请参阅Grape document, 但简单地把： 默认情况下, 第三方库被缓存在~/. groovy/grapes/Jenkins的master节点上。 Loading resources外部库可以使用libraryResource step从resources/目录加载辅助文件。该参数是一个相对路径名, 类似于 Java 资源加载:。 该文件以字符串形式加载, 适合传递给某些 api 或使用 writeFile 保存到工作区。最好使用一个唯一的包结构, 这样您就不会意外地与另一个库发生冲突。 Pretesting library changes如果您注意到在使用不受信任的库的生成中出现错误, 只需单击重播链接以尝试编辑其一个或多个源文件, 并查看所产生的生成是否按预期的方式工作。一旦你对结果满意，跟随Build状态页上的不同链接，应用不同的库变化，并保存到代码库中。 (即使为库请求的版本是一个分支, 而不是像标记这样的固定版本, 重播的生成将使用与原始生成完全相同的修订: 将不会再次签出库源。 受信任的库当前不支持重播。在重播过程中, 当前也不支持修改资源文件。 Defining Declarative Pipeline从2017年9月下旬发布的声明性1.2 开始, 可以定义声明性管道。也可在共享库中进行。下面是一个示例, 它将执行不同的声明管道, 具体取决于内部版本号是奇数还是偶数: 此时, 只能在共享库中定义整个Pipeline。这只能在”vars/*.groovy”，仅仅只能在一个方法调用中。在单个生成中只能执行一个声明性Pipeline, 如果尝试执行第二个Pipeline, 则生成结果将失败。","categories":[{"name":"Pipeline","slug":"Pipeline","permalink":"https://roclli.github.io/categories/Pipeline/"}],"tags":[{"name":"Jenkins Pipeline","slug":"Jenkins-Pipeline","permalink":"https://roclli.github.io/tags/Jenkins-Pipeline/"}]},{"title":"(原创)Pipeline4-Using-Docker-with-Pipeline","slug":"Pipeline4-Using-Docker-with-Pipeline","date":"2017-12-12T09:25:36.000Z","updated":"2017-12-13T06:35:24.647Z","comments":true,"path":"2017/12/12/Pipeline4-Using-Docker-with-Pipeline/","link":"","permalink":"https://roclli.github.io/2017/12/12/Pipeline4-Using-Docker-with-Pipeline/","excerpt":"","text":"笔者是独立翻译实验，不允许转载 Using Docker with Pipeline许多组织都是用Docker来统一编译和测试环境，提供一个发布应用的有效机制。从Pipeline 2.5版本或者更高，Pipeline内嵌支持同Jenkinsfile内Docker交互。本章覆盖了使用Jenkinsfile内Docker基本使用，并不包括Docker的使用。关于Docker使用，请参考https://docs.docker.com/get-started/。 Customizing the execution environmentPipeline较早被设计使用Docker images作为执行环境，执行一个单独的stage或者整个Pipeline，意味着用户可以定义他们的Pipeline需要使用的工具，不必手动配置代理。实践上，任何工具都能被打包到Docker container中，能被一个Jenkinsfile容易使用。 当Pipeline执行的时候，Jenkins自动开启特定的container，执行里面定义的steps。 Caching data for containers许多编译工具会下载外部依赖，并把它们缓存在本地。因为containers初始化的时候是干净的文件系统，这能导致较小的Pipelines，因此他们并不能充分利用硬盘缓存的优势。Pipeline支持添加定制化参数，参数能被传入到Docker中，允许用户指定特定的Docker Volumes去挂载，Volumes能被用来缓存代理上的数据。下面的例子将在Pipeline运行的时候，缓存~/.m2，可以避免重复下载依赖。 注意：实测表明 使用本地机器的maven repo，不用再单独下载的技巧，要点在于 (1).启动docker的时候就要传入repo (2).启动编译命令的时候，要再传一次repo，否则mvn会单独下载依赖的包 Using multiple containers现在非常普遍，代码依赖多个，不同的技术。例如一个库既有Java-based的后端API实现，也有JavaScript基础的前端实现。组合Docker和Pipeline，允许Jenkinsfile通过agent{}在不同阶段使用多种技术。 Using a Dockerfile对于那些需要特定执行环境的项目，Pipeline同样支持在Dockerfile中创建和运行容器(container)。同前面使用”off-the-shell”容器相反，使用代理{dockerfile true}语法将创建新的image，而不是从Docker Hub拉取。 重新使用前面的例子，用一个定制化的Dockerfile。 Dockerfile 把这个提交到源代码库的根目录，Jenkinsfile被改变去构建一个基于这个Dockerfile的容器，用这个容器运行定义好的steps。 agent { dockerfile true}语法支持许多其他选项，关于这些选项详见Pipeline Syntax部分。 Using a Dockerfile with Jenkins Pipeline 注意：笔者添加。 其他一些使用说明，请参见：https://github.com/jenkinsci/pipeline-model-definition-plugin/wiki/Syntax-Reference其实本例的目的：仅仅只是制作了一个新的docker image，完全可以自己手动做，也可以使用linux shell脚本和docker配合使用做出来，不一定非要通过Jenkins的插件做。此方法的一个不好的地方就是：自己设置生成的image的名字以后，通过参数加进去，最终会出来两个一样的docker image，因为再生成的时候，必须要设置一个名字，哪怕是随机的名字。参数如下：123456agent &#123; dockerfile true &#125;agent &#123; dockerfile &#123; additionalBuildArgs &apos;-t node-svn:7-alpine&apos; &#125;&#125; Specifying a Docker label默认情况下，Pipeline假设任何配置的代理都能运行基于Docker的Pipeline。对于Jenkins环境，有macOS，Windows或者其他不能运行Docker代理，默认设置可能有问题。Pipeline在Manage Jenkins页面(manage Jenkins–&gt;Configuration)上提供一个全局选项。 注意：测试表明 此label只是为了区分在哪个node上运行，本例运行的node label为:linux，其实换成master应该也可以，如果不设置，就会寻找一个默认的本地的符合条件的node执行。 Advanced Usage with Scripted PipelineRunning “sidecar” containers在Pipeline中使用Docker是运行服务/一套测试的一个有效方式，类似于sidecar模式，Docker Pipeline能在后台运行容器。使用sidecar方法，对于每一次Pipeline运行，Pipeline能有一个干净的容器。 考虑一个依赖于本地MySQL数据库的集成测试套件。使用插件docker-workflow插件实现的withRun方法，一个能运行MySQL作为sidecar的Jenkinsfile文件： 注意：本例笔者运行失败。 (1).本地必需安装有mysqladmin工具，否则执行失败。(2).docker run -d -e MYSQL_ROOT_PASSWORD=my-secret-pw -p 3306:3306 mysql:5这样启动以后，确实发现container里面的mysql启动成功，但是如果使用docker run -d -e MYSQL_ROOT_PASSWORD=my-secret-pw -p 3306:3306 mysql:5 /bin/sh进去以后，发现mysql没有启动，或者说启动失败。 示例可以更进一步，同时使用两个容器。一个”sidecar”运行MySQL，另一个用Docker container links提供执行环境。 上面的示例使用withRun暴露的对象，withRun有运行的容器ID。用容器ID，Pipeline能创建一个链接，通过传递客制化的Docker参数到inside()方法。 Id属性对于查看正在运行容器的log同样有用： 注意：笔者实测， 执行的sh命令都是在container里面执行的。所以起了两个container。 Building containers创建一个Docker image，插件docker-workflow同样提供一个build()方法创建新的image，在Pipeline运行的时候，从代码库中的Dockerfile文件也能创建image。 使用docker.build(“my-image-name”))语法的一个主要好处：脚本是的Pipeline能使用返回值用于后面的Docker Pipeline调用，例如： 返回值能被用来保存Docker image到Docker Hub或者私有的Registry，通过push()方法，例如： Image的tag属性常用方法是latest标记。push()方法接受一个可选的tag参数，允许Pipeline用不同的标记存储customImage，例如： 笔者注： 此类制作image，完全可以shell和docker独立做，如有必要，可以来此参照执行。 Using a remote Docker server默认情况下，插件docker-workflow会和本地的Docker交互，典型的是通过/var/run/docker.sock。 选择一个不是非默认Docker server，例如Docker Swarm，withServer()方法可以使用。 通过传递一个URI，可选的Docker Server Certificate Authentication认证信息，方法如下： 注意：inside()和build()将不能同Docker Swarm server正常工作。 对于函数inside()正常执行，Docker server和Jenkins代理必须使用同样的文件系统，以便工作空间能被挂载。 现在Jenkins插件和Docker CLI都不能自动检测远端server运行的case；一个典型的现象就是嵌套sh命令出现错误，例如 当Jenkins检测到代理运行在Docker容器中的时候，它将自动传递–volumes-from参数到inside容器，确保它能同代理共享工作空间。另外，一些Docker Swarm版本并不支持定制化的Registry。 Using a custom registry默认情况下，docker-workflow插件使用默认的Docker Registry—Docker Hub。为了使用定制化的Docker Registry，脚本是的Pipeline用户可以用withRegistry方法去包含steps，传递定制化的Registry URL，例如： 对于需要认证的Docker Registry，从Jenkins主页上添加用户名/密码项，并使用认证ID作为withRegistry()的第二个参数。 注意：此类是制作docker image然后保存到私有的registry，可以shell和docker实现，如有必要，来此参照制作。","categories":[{"name":"Pipeline","slug":"Pipeline","permalink":"https://roclli.github.io/categories/Pipeline/"}],"tags":[{"name":"Jenkins Pipeline","slug":"Jenkins-Pipeline","permalink":"https://roclli.github.io/tags/Jenkins-Pipeline/"}]},{"title":"(原创)Pipeline3-Branches-and-Pull-Requests","slug":"Pipeline3-Branches-and-Pull-Requests","date":"2017-12-12T09:14:44.000Z","updated":"2017-12-13T06:35:19.971Z","comments":true,"path":"2017/12/12/Pipeline3-Branches-and-Pull-Requests/","link":"","permalink":"https://roclli.github.io/2017/12/12/Pipeline3-Branches-and-Pull-Requests/","excerpt":"","text":"笔者是独立翻译实验，不允许转载 分支和拉取请求Branches and Pull Requests在上一节中，实现了Jenkinsfile，这个文件能被迁入到源代码版本控制中。这部分涵盖了 Multibranch Pipeline的概念, 建立在Jenkinsfile基础上, 提供更多的动态和自动功能。 Creating a Multibranch PipelineMultibranch Pipeline项目使得在同一个项目中不同的分支需要实现不同的Jenkinsfile。在一个Multibranch Pipeline项目中，Jenkins将为不同分支的Pipelines自动发现/管理/执行，不同的分支都包含一个Jenkinsfile文件。 这将减少人工Pipeline的创建和管理。 创建一个Multibranch Pipeline： •在Jenkins home页上点击”new Item”。 •为你的Pipeline输入名字，选择Multibranch Pipeline，然后点击OK。 注意：Jenkins用Pipeline的名字在磁盘上创建目录。包含空格的Pipeline名字可能有未查到的bug，脚本不期望路径包含空格。 •添加一个Branch Source(例如Git)，输入源代码库的地址。 •保存多分支Pipeline项目。 一旦保存，Jenkins将自动扫描代码库，为库中包含Jenkinsfile的每一个分支创建合适的项。 默认情况下，Jenkins不会自动索引用于分支添加或删除的存储库 (除非使用组织文件夹), 因此将 Multibranch Pipeline配置为定期索引在配置中通常很有用: 附加的环境变量(Additional Environment Variables)Multibranch Pipeline暴露了关于分支的附加信息，分支可以通过全局变量env创建，例如：BRANCH_NAME 这个Pipeline将要被执行的分支，例如master分支。CHANGE_ID 各种改变请求的标识符，例如a pull request号码/数字。 支持Pull Requests(Supporting Pull Requests)GitHub或者Bitbucket分支源，Multibranch Pipeline能被用来验证pull/change请求。这个功能被插件github-branch-source和插件cloudbees-bitbucket-branch-source提供。请查阅相关文档得到如何使用的进一步信息。 使用组织目录(Using Organization Folders)Organization Folder使Jenkins能监控整个GitHub组织或者Bitbucket Team/Project，自动为代码库创建新的Multibranch Pipeline项目，代码库包含分支和包含Jenkinsfile的pull request。现在，这个功能仅仅存在于GitHub和bitbucket，功能分别被插件github-branch-source和插件cloudbees-bitbucket-branch-source提供。","categories":[{"name":"Pipeline","slug":"Pipeline","permalink":"https://roclli.github.io/categories/Pipeline/"}],"tags":[{"name":"Jenkins Pipeline","slug":"Jenkins-Pipeline","permalink":"https://roclli.github.io/tags/Jenkins-Pipeline/"}]},{"title":"(原创)Pipeline2-Using-a-Jenkinsfile","slug":"Pipeline2-Using-a-Jenkinsfile","date":"2017-12-12T07:54:10.000Z","updated":"2017-12-13T06:35:16.595Z","comments":true,"path":"2017/12/12/Pipeline2-Using-a-Jenkinsfile/","link":"","permalink":"https://roclli.github.io/2017/12/12/Pipeline2-Using-a-Jenkinsfile/","excerpt":"","text":"笔者是独立翻译实验，不允许转载 Using a Jenkinsfile这部分基于前面Getting Started所讲过的信息，介绍更有用的步骤(steps)，一般模式，一些非试用的Jenkinsfile例子。 创建一个Jenkinsfile，然后把这个文件保存到源代码版本控制中(例如svn，git等)，会带来许多好处： 对Pipeline中进行代码审查和迭代(review/iteration) Pipeline的审核和跟踪 Pipeline唯一的真相来源，可以由项目的多个成员查看和编辑。 Pipeline支持两种语法: 声明式 (在Pipeline2.5 中引入) 和脚本Pipeline。两者都支持构建持续集成的Pipeline。都可以被用来定义一个Pipeline，不管是在web UI上还是在Jenkinsfile文件中，一般认为最好的实践是创建一个Jenkinsfile文件，并放到源代码管理库中。 Creating a Jenkinsfile像前面Getting Started章节讨论的一样，Jenkinsfile文件是一个文本文件，包含一个Jenkins Pipeline定义。考虑如下部分，实现了一个三阶段的持续集成pipeline。 并不是所有的Pipelines都有同样的三个阶段，但是对于大多数项目来说，这是一个很好的开始。下面的部分将说明一个简单的Pipeline的创建和执行。 注意：假设已经为项目创建好了源代码版本库，并且一个Pipeline已经按照前面Getting Started步骤定义好了。 用一个支持Groovy语法高亮的文本编辑器，创建一个新的Jenkinsfile文件，放到项目的根目录下。 上面声明式的Pipeline例子包含实现一个持续集成pipeline最小的必须的结构。Agent指示符是必须的，告诉Jenkins为这个pipeline分配一个执行器和工作空间。没有agent指示符，不仅申明式的Pipeline不是合法的，而且它也不能做任何工作！默认情况下，agent指示符确保源代码库代码被签出，并且是有效的可以被后面阶段的步骤(steps)使用。 对于一个有效的申明式的Pipeline，stage指示符和steps指示符同样是必须的，因为它们告诉Jenkins执行什么，哪个阶段做什么事情。 对于脚本式Pipeline的更高级用法，上面例子中的node是至关重要的第一步，因为它为Pipeline申请了执行器和工作空间。确切的说，没有node，一个Pipeline不能做任何工作！在node里面，业务的第一个命令将是迁出源代码。因为Jenkinsfile文件是直接从源代码库中迁出，所以Pipeline提供了一个快速和容易的方式存取正确的源代码版本。 ① checkout步骤将从源代码库中迁出代码；scm是一个特殊的变量，它将告诉checkout克隆特定的版本，然后触发Pipeline运行。 注意，笔者实测如下： 在脚本式Pipeline中checkout([$class: ‘GitSCM’, branches: [[name: ‘*/master’]], doGenerateSubmoduleConfigurations: false, extensions: [], submoduleCfg: [], userRemoteConfigs: [[url: ‘https://gitee.com/roclli/simple-maven-project-with-tests.git&#39;]]])。 申明式Pipeline(Jenkinsfile中)，采用checkout scm，会导致checkout两次，根据说明Specify where to obtain a source code repository containing your Groovy script. It will be checked out somewhere on the Jenkins master and used to load your Pipeline script. (If you wish to use other files from the same repository during your Pipeline, you will need to check them out separately on some slave; this checkout cannot be reused.)。 Build许多使用Pipeline的项目开始工作第一步都是”编译(Build)”阶段。通常情况下, Pipeline的此阶段将是源代码的组装、编译或打包。Jenkinsfile文件并不是替代现有的编译工具例如GNU/Make，Maven，Gradle等等，但可以看作是一个粘合层, 以粘合绑定(bind)项目开发的多个阶段生命周期 (构建、测试、部署等) 一起。 Jenkins有许多插件，可以调用几乎所有的构建工具，但是这个例子将简单的使用shell步骤(sh)调用make命令。sh假设系统是Unix/Linux，如果是Windows系统，将会使用bat。 ① sh调用make命令，将一直运行，如果命令返回0。任何非0的返回值都将使Pipeline失败。 ② archiveArtifacts捕获模式匹配(**/target/*.jar)文件，并且把他们保存到Jenkins的master中。 提示：存档文件不是使用外部文件资料库 (如 Artifactory 或Nexus) 的替代品, 应该只考虑基本的报告和档案存档。 Test运行自动测试是任何成功持续集成的关键组件。因此Jenkins有许多测试记录，报告，可视化插件。一般来说, 当有测试失败, 它是有用的，Jenkins会记录web UI中的报告和可视化失败。下面的示例使用junit步骤, 由junit插件提供。 下面的例子，如果运行失败，Pipeline被标记不稳定”unstable”，在网页上用一个黄色的球标记。基于记录的测试报告，Jenkins同样提供历史趋势分析和可视化报告。 ① 使用内置的shell条件(sh ‘make || true’)确保sh总是有一个0的返回值，这样使得junit机会去捕获和处理测试报告。或者使用下面的处理失败[handing-failures]部分。② Junit捕获并关联Junit XML文件，模式匹配(**/target/*.xml) 注意：此处笔者测试下来是有出入的，区别在于脚本式Pipeline 示例的stage必须放到stages里面，是和stage(‘Build’)并行的兄弟节点。 stage里的内容(sh和junit必须放到steps里面)，否则会报错。 Deploy部署可能意味着各种步骤, 具体取决于项目或组织的要求，可能是从将生成的文件发布到 Artifactory 服务器的任何东西, 或者将代码推送到生产系统。 在示例Pipeline的这个阶段，”Build”和”Test”阶段都已成功执行。因此发布阶段假设前面的阶段已经成功执行，否则Pipeline将退出。 ① 读取currentBuild.result变量允许Pipeline判断是否有失败。这种情况之下，值是UNSTABLE。 假设示例的Jenkins Pipeline都被成功执行，每一个成功的Pipeline部分都将会关联到存档文件，测试结果报告和控制台输出。 脚本式的Pipeline能包含条件测试(像上面所示)，循环(loop)，try/catch/finally块，甚至函数。接下来的部分将详细讲解脚本式Pipeline语法的高级用法。 注意：笔者测试下来 (1).期间发现过无法读取currentBuild.result变量，此时提示” Cannot get property ‘currentBuild’ on null object”，故忽略此处的Deploy。env变量也是如此提示：Cannot get property ‘env’ on null object。最后实测发现：脚本式Pipeline(web UI上面输入)，可以正确输出变量值，如下方式${env.BUILD_NUMBER}申明式Pipeline(Jenkinsfile)，可以正确输出变量值，如下方式${env.BUILD_NUMBER}可以正确用echo输出值，也可以用if判断值。代码如下：12345678echo &quot;---$&#123;env.BUILD_NUMBER&#125;---&quot;echo &quot;---$&#123;currentBuild.result&#125;---&quot;if(currentBuild.result == null || currentBuild.result == &apos;SUCCESS&apos;) &#123; echo &quot;---currentBuild.result is:$&#123;currentBuild.result&#125;------&quot;&#125;else &#123; echo &quot;---currentBuild.result is:$&#123;currentBuild.result&#125;,so, will make publish&quot;&#125; 得到的结果如下几种情况： Cases结果全局变量备注1个skip，其他全对61/null1个error,其他全对60/UNSTABLE根据前面说明，只要有失败，就是UNSTABLE全部正确59/null (2).申明式Jenkins Pipeline(Jenkinsfile)中，使用steps有报错提示：WorkflowScript: 31: Expected a step @ line 31, column 17.。解决办法：添加script符号1234567891011121314stage(&apos;Deploy&apos;)&#123; steps &#123; script&#123; echo &quot;---$&#123;env.BUILD_NUMBER&#125;---&quot; echo &quot;---$&#123;currentBuild.result&#125;---&quot; if(currentBuild.result == null || currentBuild.result == &quot;SUCCESS&quot;) &#123; echo &quot;---currentBuild.result is:$&#123;currentBuild.result&#125;------&quot; &#125; else &#123; echo &quot;---currentBuild.result is:$&#123;currentBuild.result&#125;,so, will make publish&quot; &#125; &#125; &#125;&#125; Pipeline高级语法(Advanced Syntax for Pipeline)字符串插值(String Interpolation)Jenkins Pipeline使用与 Groovy 相同的规则来进行字符串插值。Groovy的字符串插值规则可能会让这个语言的初学者感到混乱。因为Groovy支持申明一个字符串使用单引号或者双引号，例如： 只有后一个字符串将支持基于美元符号 ($) 的字符串插值, 例如: 运行结果是： 笔者加：测试运行结果如下：12Hello Mr. $&#123;username&#125;I said, Hello Mr. Jenkins 对于Pipeline的高级特性，理解怎样使用字符串插值是很重要。 环境变量(Working with the Environment)Jenkins Pipeline通过全局变量env暴露了许多环境变量，env可以在Jenkindfile中任何地方使用。Jenkins中完整的环境变量列表请参见：localhost:8080/pipeline-syntax/globals#env(假设Jenkins运行在本地的8080端口)，环境变量包括： BUILD_ID当前的build ID，同BUILD_NUMBER一致。 JOB_NAME被执行的项目的名字，例如foo或者foo/bar。 JENKINS_URLJenkins的全URL，例如example.com:port/Jenkins/（注意：只有”System COnfiguration”中设置Jenkins URL以后才有效） 引用或使用这些环境变量可以实现, 如访问Groovy 映射, 例如: 设置环境变量(Setting environment variables)在申明式Pipeline或者脚本式Pipeline中设置环境变量是不同的。申明式Pipeline支持环境申明，而脚本式Pipeline必须使用withEnv。 ① 一个environment申明使用在pipeline块中，将对pipeline中的所有step有效。② 在stage中的environment申明将只对stage内的step有效。 参数(Parameters)声明式Pipeline支持现成的参数, 允许Pipeline接受用户通过参数指令在运行时指定参数。在脚本式Pipeline中配置参数，可以通过properties实现，关于properties我们可以在Snippet Generator中找到。 如果想要配置你的Pipeline接受Build With parameters的参数，那些参数是可以通过params变量读取。 假设一个名叫Greeting的字符串变量被配置在Jenkinsfile中，那么可以通过${params.Greeting}读取。 注意：笔者测试如下：本例如果是script(web UI上直接输入脚本方式)执行，会出现参数输入 如果是Jenkisnfile(声明式执行)，会直接使用默认值Hello。 处理失败(Handling Failures)申明式Pipeline支持健壮的错误处理，默认通过它的post section处理，post section允许申明许多不同的”post conditions”，例如always，unstable，success，failure，和changed。Pipeline语法(Pipeline Syntax)部分提供更多的细节，怎样使用不同的post情况。 脚本式Pipeline依赖于Groovy内嵌的try/catch/finally语法处理Pipeline执行期间出现的错误。 在上面的测试例子中，sh被修改永远不返回非0值(sh ‘make check || true’)。这个方法意味着接下来的阶段需要检查currentBuild.result去判断是否存在错误发生。 另一种处理此问题的方法是使用一系列try/finally 块, 它可以保留Pipeline中故障的早期退出行为, 同时仍使 junit 有机会捕获测试报告： 注意：笔者实测，申明式添加了post；其次mail的各参数，必须用单引号括起来。 申明式(Jenkinsfile)邮件发送失败，以下两种方式都失败(脚本式Pipeline无邮件部分)： mail to: ‘a@b.com’, subject: ‘The Pipeline(handing failure) failed :(‘, body: ‘this is body’ emailext body: ‘this is body’, subject: ‘title’, to: ‘ a@b.com ‘ 如果前面执行成功，那么就不会执行post里面的failure部分。 使用多个代理(Using multiple agents)在所有前面的例子中，只使用一个代理。这意味着Jenkins分配的所有执行器，只有一个是有效的，无论它是如何被标记和配置。Pipeline允许在一个Jenkinsfile中使用多个代理，这对于高级的用户案例是很帮助的，例如在多个平台上执行builds/tests。 在下面的例子中，Build阶段在一个代理上执行，build的结果将被两个子代理重用，在test阶段，标记linux和windows的两个代理是相互独立的。 ① stash允许捕获模式匹配的文件(/target/.jar)，只在同一个Pipeline其他地方重用。一旦Pipeline完成了执行，stash捕获的文件将被Jenkins master删除。 ② 在agent/node中的参数允许任何有效的Jenkins标签表达式。查阅”Pipeline Syntax” 部分可以更详细的信息。 ③ unstash 将从Jenkins主机中检索stash到Pipeline的当前工作区中。 ④ bat脚本允许在windows平台上执行脚本。 注意：笔者实测 (1).首先需要配置windows slave node，关于windows slave，需要配置master上已有的需要用到的环境变量： (2).首先分别修改两个node的label为linux(master)和windows(slave)。 可选的step参数(Optional step arguments)Pipeline遵循Groovy语言约定, 允许在方法参数周围省略括号。 许多Pipeline steps还使用命名参数语法作为在Groovy中创建映射的简写形式, 它使用语法 [key1: value1、key2: value2]。使语句像以下功能等效： 方便起见，当参数只有一个参数的时候，参数名可以省略，例如： 高级脚本Pipeline脚本Pipeline是一个domain-specific语言，基于Groovy，大多数的Groovy语法都能不用修改被用在脚本Pipeline中。 并行执行(Executing in parallel)上面部分中的示例在一个线性序列中跨两个不同的平台运行测试。实践中，如果make check需要花30分钟执行完，”Test”阶段将花费60分钟完成。 幸运的是，Pipeline具有内置的功能, 用于并行执行Pipeline脚本部分, 并在恰当命名的并行(parallel)步骤中实现。 重构上面的示例以使用并行(parallel)步骤: 不像原先的在linux和windows上线性执行，他们现在可以并行执行。","categories":[{"name":"Pipeline","slug":"Pipeline","permalink":"https://roclli.github.io/categories/Pipeline/"}],"tags":[{"name":"Jenkins Pipeline","slug":"Jenkins-Pipeline","permalink":"https://roclli.github.io/tags/Jenkins-Pipeline/"}]},{"title":"(原创)Pipeline1-Getting-Started-With-Pipeline","slug":"Pipeline1-Getting-Started-With-Pipeline","date":"2017-12-12T07:12:55.000Z","updated":"2017-12-13T06:35:11.279Z","comments":true,"path":"2017/12/12/Pipeline1-Getting-Started-With-Pipeline/","link":"","permalink":"https://roclli.github.io/2017/12/12/Pipeline1-Getting-Started-With-Pipeline/","excerpt":"","text":"前言(笔者自己添加部分) 最好的资料莫过于官方文档，旧文档不再维护。所以本文其实是翻译并实践学习pipeline，对应的pdf文档，已上传到csdn 笔者是独立翻译实验，不允许转载 本文直接从Pipeline开始，如果对Jenkins不熟悉，请参见Jenkins官方文档或者本系列的第一章Installing Jenkins。 Pipeline本章将会学习Jenkins Pipeline的所有特性，从运行Pipeline到写Pipeline代码，甚至扩展到Pipeline本身。 本章可以被Jenkins各个水平的用户使用，但是初学者可能要参考下本书”Using Jenkins”的章节去理解本章的一些专有名词。 如果还没有熟悉最基本的Jenkins技术和特点，请从”Getting Started with Jenkins”开始。 What is Jenkins Pipeline?Jenkins Pipeline(或者简单用一个大写字母P代替”Pipeline”)是一套插件，这套插件支持实现和整合持续集成pipelines(continuous delivery pipelines)到Jenkins中。 持续集成Pipeline (continuous delivery pipelines)是一个程序自动进行的过程, 用您的用户和客户的版本控制权获取软件。对软件的每次更改(在源代码管理中提交)经过一个复杂的过程, 用它的方式发布软件(release)。这个过程包括以一个可靠地可重复的方式去构建软件，就像通过测试和发布(deployment)的多个步骤去构建(build)软件过程一样。 Pipeline提供一套可扩展的工具集，用代码去模型化简单到复杂的(simple-to-complex)发布pipelines，代码使用Pipeline Domain Specific Language(DSL)语法。 通常, Jenkins Pipeline的定义被写入文本文件 (称为 Jenkinsfile)，文件被放到项目的源代码管理存储库中[3: Source Control Management]。这是Pipeline代码(Pipeline-as-Code)的基础；把持续集成作为应用的一部分用版本控制，并且像其他代码一样可以review。创建Jenkinsfile有很多好处： 自动为所有的分支和pull requests创建Pipelines 在Pipeline中进行代码审查和迭代(review/iteration) Pipeline的审核和跟踪 Pipeline唯一的真相源 [4: en.wikipediaorg/wiki/Single_Source_of_Truth]，可以由项目的多个成员查看和编辑。定义Pipeline的语句，要么在web UI中，要么在一个Jenkinsfile文件中，一般认为最好的体验是，定义Pipeline在Jenkinsfile文件中，并且放到源代码版本控制中(例如git，svn等)。这是一个Jenkinsfile文件例子： ① agent表明Jenkins要为Pipeline的这部分分配一个执行器和工作空间。 ② stage表明是这个Pipeline的一个stage。 ③ steps这个stage将要运行的一个步骤。 ④ sh执行给与的shell语句。 ⑤ junit是一个Pipeline步骤，Junit插件提供用来搜集测试报告。 Why Pipeline?Jenkins基本上是一个自动化引擎, 它支持许多自动化模式。Pipeline添加了一套强有力的自动化工具集到Jenkins，支持从简单持续集成到综合持续集成的用例，到Pipeline。通过将一系列相关任务模型化，用户能充分利用Pipeline许多特性的优势。 Code：Pipeline是用代码实现，能做版本控制，可以给团队编辑/检查/迭代Pipeline的能力。 Durable：Pipeline可以在计划的和未计划的Jenkins主机重启中不受影响。 Pausable：Pipeline在继续运行之前，可以选择停止/等待输入或者批准。 Versatile：Pipeline能满足现实世界复杂的持续集成需求，包括并行执行fork/join/loop。 Extensible：Pipeline插件支持定制化的扩展到它自己的DSL[2: Domain-Specific Language]。 虽然Jenkins一直允许基本形式的链接自由式Jobs[5: Additional plugins have been used to implement complex behaviors utilizing Freestyle Jobs such as the Copy Artifact, Parameterized Trigger, and Promoted Builds plugins]，一起执行顺序任务, Pipeline使这个概念成为Jenkins的一流插件。基于Jenkins可扩展的核心价值，Pipeline同样是可扩展的。下图是一个持续集成的例子，可以很容易被模型化。 Pipeline 关键字Step 一个独立的任务；一般来说steps告诉Jenkins做什么。例如执行shell命令，用sh执行make：sh ‘make’。当插件扩展Pipeline DSL，这意味着插件能执行一个新的step。 Node Pipeline执行的大多数工作是在一个或多个声明的Node的上下文中完成的。限制Node 步骤内的工作有两点： (1).将块中包含的steps，通过向Jenkins添加项来运行队列.一旦一个执行器在一个节点上是空闲的, 这些steps就会运行。 (2).创建工作区 (特定于该特定Pipeline的目录)，在工作区里，工作能被完成。 注意： 取决于你的Jenkins配置，经过一段时间的不活动时期之后，一些工作区不能被自动清除。可以查看JENKINS-2111得到更多的信息。 Stage Stage是定义整个Pipeline概念上子集的一个步骤，例如”Build”，”Test”，和”Deploy”，这被许多插件使用来可视化或者表现pipeline状态/进度。[5: Blue Ocean, Pipeline Stage View plugin] 开始Pipeline(Getting Started with Pipeline)Jenkins Pipeline是一套支持持续集成的插件。Pipeline提供扩展的工具，通过Pipeline DSL去模型化简单到复杂的代码发布Pipeline。 本部分介绍一些Jenkins Pipeline的基本概念，例如基本的定义，用Pipeline执行任务。 前提条件使用Jenkins Pipeline，你会需要： Jenkins 2.x或者更高版本(更老版本1.642.3可能可以，但是不推荐) Pipeline插件[6: Pipeline plugin] 想知道怎样安装和管理，请参见 Managing Plugins。 定义PipelinePipeline脚本是用Groovy语言撰写。于是本文会介绍一些相关的Groovy语法，理解Groovy是有帮助的，但并不是必需的。 一个基本的Pipeline能按照以下两种方式创建： Jenkins web UI上直接输入脚本 创建一个Jenkinsfile文件，这个能被放到代码版本控制软件中。 用任意方法定义Pipeline的语法是相同的, 但Jenkins支持将Pipeline直接输入到 web UI 中, 通常认为最好的做法是定义在Jenkinsfile的Pipeline, Jenkins将直接从源代码管理加载。 在web UI中定义一个Pipeline在web UI中创建一个基本的Pipeline。跟随以下步骤： 点击Jenkins首页上的”New Item”。 为Pipeline输入一个名字，选择Pipeline，然后点击OK。 注意：Jenkins用Pipeline的名字在硬盘上创建目录。包含空格的Pipeline名字可能会有bugs，脚本并不支持包含空格的路径。 在Script区域，输入一个Pipeline，然后点击Save。 点击”Build Now”去运行Pipeline。 点击”build History”下的#1，然后点击Console Output去查看Pipeline完整的输出。 上面的例子展示了一个成功的Pipeline运行情况，用了两步。 ① node分配一个执行器和工作空间。 ② echo在Console Output输出字符串。 在SCM中定义一个Pipeline复杂的Pipeline很难在Pipeline配置区域去写和维护。为了让这个更容易一些，Pipeline同样可以用文本编辑器写并放到版本控制中，通过Pipeline Script from SCM选项，Jenkins可以装载Jenkinsfile文件。 要做到这一点，当定义一个Pipeline时，选择”Pipeline Script from SCM”选项。 随着”Pipeline Script from SCM”选项被选择，在Jenkins界面上，你不能直接输入任何Groovy代码；你只能输入一个源代码路径，从这个路径可以找到pipeline文件。当更新代码库的时候，一个新的编译被触发，只要Pipeline被配置使用SCM polling触发。 提示： Jenkinsfile的第一行应该是#!/usr/bing/env groovy，这样文本编辑器，IDEs，GitHub等可以按照Groovy代码来语法高亮Jenkinsfile文件。 内建文档(Built-in Documentation)随着Pipeline一起发布的内建的文档，使得创建复杂的Pipelines更加容易。内建的文档可以根据安装在Jenkins实例中的插件，被自动生成和更新。 内建的文档可以通过链接被找到: localhost:8080/pipeline-syntax/。假设你已经有了一个正运行在本地8080端口上的实例。同样的文档可以连接到这里，通过任何项目的左边菜单”Pipeline Syntax”。 代码段生成器(Snippet Generator)内建的代码段生成器(Snippet Generator)功能对于以下功能很有帮助，创建独立步骤地代码，发现插件提供的新步骤，对于一个特定的步骤实验不同的参数。 代码段生成器是动态填充的, 其中列出了可供Jenkins使用的步骤。可用的步骤数取决于安装的插件, 它显式地公开了Pipeline可使用的步骤。 使用代码生成器，生成步骤 (1).导航到Pipeline Syntax链接。 (2).在Sample Step下达菜单中，选择需要的步骤。 (3).使用Sample Step下拉菜单下面的动态区域去配置选定的步骤。 (4).点击Gemerate Pipeline Script生成一个代码段，拷贝到Pipeline中。 存取选定步骤的附加信息，点击Help按钮()上图红色箭头所指部分。 Global Variable Reference除了代码段生成器(Snippet Generator)只能生成步骤之外，Pipeline同样提供了一个内建的”Global Variable Reference”。像代码段生成器(Snippet Generator)一样，它也是被插件动态生成的。不像代码段生成器(Snippet Generator)的是，Global Variable Reference仅仅包含Pipeline或者插件提供的变量文档，只对Pipeline有效。 Pipeline默认提供的变量有： env 环境变量可以被Pipeline脚本，例如env.PATH或者env.BUILD_ID。可以到Global Variable Reference寻找，到目前为止，完整的，最新的，Pipeline中可以使用的变量列表。 params 将为Pipeline定义的所有参数公开为只读映射, 例如:params.MY_PARAM_NAME currentBuild 可以被用来发现当前正在执行的Pipeline的相关信息，例如currentBuild.result，currentBuild.displayName等等。可以到Global Variable Reference寻找，到目前为止，完整的，最新的，可以用的currentBuild列表。 Further Reading本章节仅仅只说出了Jenkins Pipeline能做的一小部分，但已经为你提供了足够多的基础，去开始实验Jenkins实例。 下一节Jenkinsfile，更多的Pipeline步骤将被讨论。 Additional Resources Pipeline Steps Reference, 包含发布插件提供的所有步骤 Pipeline Examples，可拷贝社区版的Pipeline例子集合。 参考资料： https://jenkins.io/doc/book/pipeline/ https://en.wikipedia.org/wiki/Domain-specific_language https://en.wikipedia.org/wiki/Version_control https://en.wikipedia.org/wiki/Single_source_of_truth https://wiki.jenkins-ci.org/display/JENKINS/Pipeline+Stage+View+Plugin https://plugins.jenkins.io/workflow-aggregator ../managing/plugins.pdf","categories":[{"name":"Pipeline","slug":"Pipeline","permalink":"https://roclli.github.io/categories/Pipeline/"}],"tags":[{"name":"Jenkins Pipeline","slug":"Jenkins-Pipeline","permalink":"https://roclli.github.io/tags/Jenkins-Pipeline/"}]},{"title":"Java OOM ERROR","slug":"Java-OOM-ERROR","date":"2017-12-11T05:44:57.000Z","updated":"2017-12-13T06:34:44.620Z","comments":true,"path":"2017/12/11/Java-OOM-ERROR/","link":"","permalink":"https://roclli.github.io/2017/12/11/Java-OOM-ERROR/","excerpt":"","text":"Java内存溢出(OOM异常完全指南),原文见:http://www.jianshu.com/p/2fdee831ed03作者CHEN川是从这里翻译来的:https://plumbr.io/outofmemoryerror笔者是独立翻译实验，不允许转载 java.lang.OutOfMemoryError:Java heap spaceJava应用程序被允许使用有限的内存。这个限制在程序开始运行的时候就被说明了。为了便于处理，Java内存被分成两个区域，分别称为：堆内存/堆空间(Heap space)和永久代(Permgen, Permanent Generation)。 这两个区域的大小可以在JVM(Java虚拟机)启动时通过参数-Xmx和-XX:MaxPermSize设置。如果你不显示指定大小，将使用特定平台的默认值。 当应用程序试图添加更多的数据到堆空间区域，却没有足够空间，此时java.lang.OutOfMemoryError: Java heap space error将被触发。注：系统可能有许多未使用的物理内存，但是当JVM到达堆空间大小限制的时候，java.lang.OutOfMemoryError: Java heap space error异常仍然会被抛出。注意(编者加)：上面的JVM内存模型是JDK7的模型，在JDK8中已经移除了永久代，取而代之的是MetaSpace(主要存放类的元数据)。 原因分析(What is causing it)：触发java.lang.OutOfMemoryError: Java heap space error异常的常见原因：应用程序需要XXL号的堆内存，但是却提供了一个s号的堆内存。也就是说：应用程序需要比它所能得到的更大的堆内存。其它引发OutOfMemory的原因更加复杂，也有可能是程序原因。 使用/数据量峰值：应用程序在设计之初要考虑处理大量的用户和大量的数据。当大量的用户或者数据突然到达峰值，并且超过了预期的阈值，以前在峰值到达之前功能正常的操作将会停止，并且触发java.lang.OutOfMemoryError异常。 内存泄漏：一种特殊的编程错误将会导致应用程序持续消耗更多的内存。每一次有内存泄漏功能的应用程序使用，都将留下一些对象在java堆空间中，随着时间的推移，泄露的对象消耗越来越多的java堆空间，就触发了我们熟悉的java.lang.OutOfMemoryError异常。 示例简单示例第一个应用程序非常简单–下面的java代码试图申请一个2M的数组。当编译并以一个12M(java -Xmx12m OOM)的堆内存运行的时候，将会失败，并且提示：Java.lang.OutOfMemoryError: Java heap space message。如果给与13M的堆内存，程序将运行很好。123456class OOM &#123; static final int SIZE=2*1024*1024; public static void main(String[] a) &#123; int[] i = new int[SIZE]; &#125;&#125; 运行结果如下：Exception in thread “main” java.lang.OutOfMemoryError: Java heap space at OOM_heapspace.main(OOM_heapspace.java:7) 内存泄漏示例在Java中，当开发者创建和使用新的对象，例如new Integer(5)，他们不用自己分配内存–这个工作是Java虚拟机(JVM)来做的。在整个应用程序生命周期中，JVM会定期检查，内存中的哪些对象仍然在使用，哪些对象没有继续使用。不再使用的内存对象会被回收，并被重新分配和再使用。这个过程称之为垃圾回收（Garbage Collection）。JVM执行这个功能的模块被称为Garbage Collector(GC)。 Java的自动内存管理依赖于GC定期的寻找不再使用的对象并且移除他们。 简单来说，我们可以说：在Java中的内存泄漏是这样一种情况，一些对象不再被应用程序使用，但是GC却没办法识别他们。因此这些不再被使用的对象仍然无限期的保留在Java的堆空间中。这样的堆积最终将触发java.lang.OutOfMemoryError: Java heap space异常。很容易新建一个java程序来满足内存泄露的定义。 123456789101112131415161718192021class KeylessEntry &#123; static class Key &#123; Integer id; Key(Integer id) &#123; this.id = id; &#125; @Override public int hashCode() &#123; return id.hashCode(); &#125; &#125; public static void main(String[] args) &#123; Map m = new HashMap(); while (true) for (int i = 0; i &lt; 10000; i++) if (!m.containsKey(new Key(i))) m.put(new Key(i), &quot;Number:&quot; + i); &#125;&#125; 当执行上面的代码，我们可能会认为程序会一直跑下去，没有任何问题，认为存储在缓存中的Map将扩展到10000个元素，再往下，所有的Key都已经在HashKey中存在了。然而，实际情况是Key class的元素并不包含equals这个方法的实现。 因此，随着时间的继续，泄露内存代码的持续运行，会导致消耗大量java堆空间。当持续占满所有可用的堆空间，并且GC不能清除的时候，就会触发java.lang.OutOfMemoryError: Java heap space异常。 解决方案非常简单–添加equals()方法的实现，这样代码就能很好的运行。 12345678@Overridepublic boolean equals(Object o) &#123; boolean response = false; if (o instanceof Key) &#123; response = (((Key)o).id).equals(this.id); &#125; return response;&#125; 解决方案某些情况，我们分配给JVM堆空间的内存数量不能满足程序运行的需求。此时，我们应该分配更多的堆空间，看本文的结尾如何做。 然而，在更多情况下，提供更多堆空间并不能解决问题。例如应用程序有内存泄漏，添加更多的堆内存只会推迟java.lang.OutOfMemoryError: Java heap space异常。另外，增加堆空间数量也会增加GC暂停的次数进而影响应用程序的吞吐量或者延迟(latency). 如果希望解决Java堆空间的潜在问题，而不是掩盖问题，那么我们需要搞清楚代码的哪一部分负责申请内存。换句话说，必须回答以下问题： 哪些对象占据了堆空间的大部分 这些对象在源代码的位置 在这一点上，一定要确信搞清楚。下面是一个大致的大纲，这个大纲将帮助我们回答上面的问题： 获得安全许可，以便从JVM执行heap dump。”Dumps”基本上来说是对堆内容的快照，这些内容是我们可以分析的。这些快照包含了关键信息，例如密码，信用卡号码等等，由于安全原因，我们甚至不太可能获取这些快照。 在合适的时刻得到dump文件。错误的时间得到一些dumps文件，堆dump文件包含大量的无用内容。另一方面，每一个堆dump包含了jvm的所有内容，因此不要做太多次的dump操作，否则客户也需要面对性能问题。 找到一台能够读取dump文件的机器。在开始执行JVM问题调查的时候，例如一个8GB的堆，我们需要一台超过8GB去分析堆内容。至于用来分析dump文件的软件(我们推荐Eclipse MAT，当然也有其它许多优秀的软件，例如JProfiler/YourKit)。注：到现在为止Jprofiler10为最新版，找不到合适的license。因此使用Jprofiler9.2，是好用的。 检查堆空间最大消费者的GC根目录的路径。我们已经做过这件事情，有一个单独的文章，请参见这里。对于初学者来说有些困难，但是实践将会使我们理解结构和机制。 接下来，我们需要搞清楚代码中，哪些代码申请了大量内存。如果对自己的应用程序的源代码有很好了解的话，那么几次搜索就能做完这件事情。 解决方案就是增大堆空间-Xmx1024m再例如所有下面的配置具有同样功能，因为我们可以使用g/G/m/M/k/K。例如所有如下配置都是相同的，最大堆空间是1GB： 1234java -Xmx1073741824 com.mycompany.MyClassjava -Xmx1048576k com.mycompany.MyClassjava -Xmx1024m com.mycompany.MyClassjava -Xmx1g com.mycompany.MyClass java.lang.OutOfMemoryError:GC overhead limit exceededJRE(Java Runtime Environment)包含了一个自带/内嵌的GC(Garbage Collection)程序。在许多其它编程语言中，开发者需要自己申请和释放内存。 另一方面，Java程序只需要申请内存即可。当内存中一个空间不再使用的时候，一个独立的称作GC的进程将清除这些不再使用的内存。GC是如何检测内存中特殊区域，详细情况请见：Garbage Collection Handbook，但是我们应该信任GC能做好它的工作(内存回收)。 java.lang.OutOfMemoryError: GC overhead limit exceeded异常将被触发，当应用程序消耗了所有可用的内存，GC还在不停的清除内存，并且清除内存一直失败。 原因分析：java.lang.OutOfMemoryError: GC overhead limit exceeded异常，是JVM发出的一个信号，表明：应用程序花费了太多时间在做内存回收的工作，回收结果却不好。默认情况下，JVM将会报错，如果花费超过98%时间在执行GC操作，却仅仅回收了不到2%的内存。 如果GC overhead limit不存在，将会发生什么事情？java.lang.OutOfMemoryError: GC overhead limit exceeded异常只有在这种情况下才会被触发，经过几次GC循环操作之后，只释放了2%的内存。这意味着只有少量的堆空间能被清除，这些空间将会被很快再次用掉，强迫GC再次重新开始清除进程。这就形成了一个恶性循环，CPU100%被用于GC操作，没办法做其他事情了。应用的终端用户感觉非常慢-通常毫秒级别完成的操作，现在却需要数分钟才能完成。 于是”java.lang.OutOfMemoryError: GC overhead limit exceeded”提示可以看做”fail fast”规则一个非常棒的例子。 实例下面的例子，我们将创建一个GC overhead limit exceeded异常，通过初始化一个MAP，通过无限循环添加key-value对到map中。123456789class Wrapper &#123; public static void main(String args[]) throws Exception &#123; Map map = System.getProperties(); Random r = new Random(); while (true) &#123; map.put(r.nextInt(), &quot;value&quot;); &#125; &#125;&#125; 你有可能猜到，这段代码可能不能很好的结束。确实，当用下列配置运行这段代码的时候，123java -Xmx100m -XX:+UseParallelGC Wrapperjava -Xmx10m -XX:+UseParallelGC Wrapperjava -Xmx20m -XX:+UseParallelGC Wrapper 错误信息如下(使用JDK7)：Exception in thread “main” java.lang.OutOfMemoryError: Java heap space at java.util.Hashtable.rehash(Hashtable.java:402) at java.util.Hashtable.addEntry(Hashtable.java:426) at java.util.Hashtable.put(Hashtable.java:477) at GC_ole.main(GC_ole.java:11)当使用如下参数java -Xmx2m -XX:+UseParallelGC Wrapper，错误信息如下：Exception in thread “main” java.lang.OutOfMemoryError: GC overhead limit exceeded at java.util.Hashtable.put(Hashtable.java:541) at GC_ole.main(GC_ole.java:11) 不久，我们就将看到java.lang.OutOfMemoryError: GC overhead limit exceeded异常。但是如果我们配置不同的堆空间大小或者不同的GC算法，结果会有不同。例如，用如下方式在ubuntu16.04，用Hotspot1.7.0_80运行： java -Xmx10m -XX:+UseParallelGC Wrapper我们将看到如下错误：Exception in thread “main” java.lang.OutOfMemoryError: Java heap space at java.util.Hashtable.rehash(Hashtable.java:471) at java.util.Hashtable.put(Hashtable.java:532) at GC_ole.main(GC_ole.java:11) 使用以下GC算法：-XX:+UseConcMarkSweepGC 或者-XX:+UseG1GC，启动命令如下： java -Xmx100m -XX:+UseConcMarkSweepGC Wrapper java -Xmx100m -XX:+UseG1GC Wrapper得到的结果是这样的：Exception: java.lang.OutOfMemoryError thrown from the UncaughtExceptionHandler in thread “main”错误已经被默认的异常处理程序捕获，并且没有任何错误的堆栈信息输出。以上这些变化可以说明，在资源有限的情况下，你根本无法无法预测你的应用是怎样挂掉的，什么时候会挂掉，所以在开发时，你不能仅仅保证自己的应用程序在特定的环境下正常运行。 解决方案如果我们仅仅想去掉java.lang.OutOfMemoryError: GC overhead limit exceeded这个消息，添加下列到启动脚本里面就可以做到：-XX:-UseGCOverheadLimit烈建议不要这样做–应该修复解决这个问题，而不是将这个不可避免的问题推迟或者延后；因为应用程序将会把内存用尽。错误信息也变成了更加熟悉的java.lang.OutOfMemoryError: Java heap space而已。 某些情况下，GC overhead limit exceeded异常被触发，因为申请的内存不能满足程序运行的需要。此时，应该申请更多的内存–看本文末尾如何做到这一点。例如应用程序存在内存泄漏，将推迟java.lang.OutOfMemoryError: Java heap space异常。另外增加内存将增加GC暂停的时间长度，影响到应用程序的吞吐量和延迟等。 如果希望解决Java堆空间的潜在问题，而不是掩盖问题，那么我们需要搞清楚代码的那一部分负责申请内存。换句话说，必须回答以下问题： 哪些对象占据了堆空间的大部分 这些对象在源代码的位置 在这一点上，一定要确信搞清楚。下面是一个大致的大纲，这个大纲将帮助我们回答上面的问题： 通过安全检查，以从JVM执行heap dump。”Dumps”基本上来说是对内容的快照。这些快照包含了关键信息，例如密码，信用卡号码等等，由于安全原因，我们甚至不太可能获取这些快照。 在合适的时刻得到dump文件。错误的时间得到一些dumps文件，堆dump文件包含大量的无用内容。另一方面，每一个堆dump包含了jvm的所有内容，因此不要做太多次的dump操作，否则客户也需要面对性能问题。 找到一台能够读取dump文件的机器。在开始执行JVM问题调查的时候，例如一个8GB的堆，我们需要一台超过8GB去分析对内容。至于用来分析dump文件的软件(我们推荐Eclipse MAT，当然也有其它许多优秀的软件，例如JProfiler/YourKit)。注：到现在为止Jprofiler10为最新版，找不到合适的license。因此使用Jprofiler9.2，是好用的。具体请参见百度云盘jprofiler目录。 检查堆空间最大消费者的GC根目录的路径。我们这个分析，有一个单独的文章，请参见这里。对于初学者来说有些困难，但是实践将会是我们理解结构和机制。 接下来，我们需要搞清楚代码中，哪些代码申请了大量内存。如果对自己的应用程序的源代码有很好的了解的话，那么几次搜索就能做完这件事情。 java.lang.OutOfMemoryError:Permgen spaceJava应用程序只被允许使用有限的内存。确切使用的内存数量只能在程序开始运行时才能知道。Java内存被分成不同的区域，如下图所示： 注：此为JDK7的jvm内存模型。上图所有的区域包括永久代都是在JVM开始运行的时候被设定。如果不设置，将会使用特定平台的默认值。java.lang.OutOfMemoryError: PermGen space消息表明：内存中的永久代区域已经被用完了。 原因分析要想理解java.lang.OutOfMemoryError: PermGen space的原因，我们需要知道这块内存区域的用途：为了实践目的，永久代包含大多数的类定义，也就是类/方法的名字和字段，全局不可变变量池，对象数组，类相关的对象数组，实时编译优化等。从上面的定义，我们可以看出，永久代的大小取决于类申明的数量和装载的类的数量。因为，我们可以说：java.lang.OutOfMemoryError: PermGen space的主要原因：要么太多的类，要么太大的类被分配到了永久带空间。 实例简单实例综上所述，永久带空间的使用是和加载到jvm的类的数量强相关的。下面是一个简明的例子：123456789101112import javassist.ClassPool;public class MicroGenerator &#123; public static void main(String[] args) throws Exception &#123; for (int i = 0; i &lt; 100_000_000; i++) &#123; generate(&quot;com.myown.demo.Generated&quot; + i); &#125; &#125; public static Class generate(String name) throws Exception &#123; ClassPool pool = ClassPool.getDefault(); return pool.makeClass(name).toClass(); &#125;&#125; 在这个示例中，通过循环逐个生成运行时类。类的生成是javassist库负责。 运行上面的代码将持续生成新类并把他们的定义装载到永久代空间，直到空间被全部使用，java.lang.OutOfMemoryError: PermGen space异常就会被触发。实际测试发现(Ubuntu16.04 JDK7，设置-XX:MaxPermSize=512m,否则内存空间占据太多),报错如下：Exception in thread “main”Exception: java.lang.OutOfMemoryError thrown from the UncaughtExceptionHandler in thread “main”为什么不是java.lang.OutOfMemoryError: PermGen space异常,从监控看，PermGen空间确实满了，heap有剩余。 重新部署示例再说一个更加复杂和更加实际的例子，在程序重新部署发布的时候，我们经历一次java.lang.OutOfMemoryError: PermGen space异常的发生。当我们重新发布应用程序的时候，我们希望GC能清除以前的旧的已经装载的类，并重新装载新版本的类。 不幸的是，许多第三方类和资源的处理，例如线程，JDBC驱动或者文件系统处理，不能卸载旧类。这也意味着：每一次重新发布，所有先前版本的类仍然存在于永久代空间，并且每次重新发布都会生成几十M的垃圾数据。 想象一个例子，应用使用JDBC连接到一个关系型数据库。当应用开始的时候，代码初始化JDBC驱动去连接数据库。根据说明，JDBC驱动会注册他自己为java.sql.DriverManager。注册会存储一个引用，这个引用指向到一个DrvierManager实例的静态字段。 现在，当从服务器上卸载应用程序的时候，java.sql.DriverManager仍将持有那个驱动程序的引用，进而持有用于加载应用程序的classloader的一个实例的引用，通常会占有数十兆的永久代空间。这个classloader现在仍然引用着应用程序的所有类。这意味着经历过几次重新部署，就会触发java.lang.OutOfMemoryError: PermGen space错误。 解决方案 .解决初始化时的OutOfMemoryError 当OutOfMemoryError因永久代耗尽被触发的时候(应用程序启动的时候)，解决方案非常简单。应用程序需要更多的空间去家在所有的类到永久代区域。我们增大永久代的大小，提示应用程序增大永久带空间。-XX:MaxPermSize相似的参数： java -XX:MaxPermSize=512m com.yourcompany.YourClass 上面的配置告诉JVM，永久代最大空间可以到512M。 解决重新发布的OutOfMemoryError 当重新发布应用的时候，OutOfMemoryError恰好发生了，说明应用程序遭遇了classloader泄露。此时我们应该执行堆dump分析–是用类似如下命令去执行堆dump的工作: jmap -dump:format=b,file=dump.hprof 然后用熟悉的工具去分析dump文件。如果是第三方库的原因，可以去Google/StackOverflow检查下是否是一个已知问题，如是已知问题，可以下载一个补丁或者解决方案。如果是自己代码的问题，需要及时修改。 解决运行时OutOfMemoryError 首先你需要检查是否允许GC从PermGen卸载类，JVM的标准配置相当保守，只要类一创建，即使已经没有实例引用它们，其仍将保留在内存中，特别是当应用程序需要动态创建大量的类但其生命周期并不长时，允许JVM卸载类对应用大有助益，你可以通过在启动脚本中添加以下配置参数来实现： -XX:+CMSClassUnloadingEnabled 默认情况下，这个配置是未启用的，如果你启用它，GC将扫描PermGen区并清理已经不再使用的类。但请注意，这个配置只在UseConcMarkSweepGC的情况下生效，如果你使用其他GC算法，比如：ParallelGC或者Serial GC时，这个配置无效。所以使用以上配置时，请配合： -XX:+UseConcMarkSweepGC 如果你已经确保JVM可以卸载类，但是仍然出现内存溢出问题，那么你应该继续分析dump文件，使用以下命令生成dump文件： jmap -dump:file=dump.hprof,format=b 当你拿到生成的堆转储文件，并利用像Eclipse Memory Analyzer Toolkit这样的工具来寻找应该卸载却没被卸载的类加载器，然后对该类加载器加载的类进行排查，找到可疑对象，分析使用或者生成这些类的代码，查找产生问题的根源并解决它。 java.lang.OutOfMemoryError:MetaspaceJava应用程序只被允许使用有限的内存。确切使用的内存数量只能在程序开始运行时才能知道。Java内存被分成不同的区域，如下图所示： 上面所有的区域，包括元数据区域，都是在JVM启动的时候被设定。如果没有指定，那么特定平台的默认数据将被使用。 java.lang.OutOfMemoryError: Metaspace预示着内存中的元数据空间消耗殆尽。 原因分析如果不是Java新手，那么你可能熟悉另外一个称作PermGen的Java内存管理的概念。从Java8开始，内存模型有显著的改变。一个新的被称为Metaspace的内存区域被引进，PermGen被移除了。这个改变有多种原因，包括但不限于以下： 永久代(PermGen)的大小很难预测。这直接导致了要么触发java.lang.OutOfMemoryError: Permgen size异常，要么浪费资源。 GC效率的提升改进，使得并发类数据重新申请内存不再进行GC暂停(GC pause)和指定元数据遍历。 支持进一步的优化，例如G1并发类卸载。如果熟悉PermGen，那么也知道它的作用–在java8以前，所有类的名字、字段、方法，字节方法，变量池，JIT优化等都是存储在PermGen中，现在都在Metaspace中。 正如你所看到的，元空间大小的要求取决于加载的类的数量以及这种类声明的大小。 所以很容易看到java.lang.OutOfMemoryError: Metaspace主要原因：太多的类或太大的类加载到元空间。 实例正如前面解释的，Metaspace是和加载的类的数量密切相关。下面的代码是一个简单明了的说明：12345678public class Metaspace &#123; static javassist.ClassPool cp = javassist.ClassPool.getDefault(); public static void main(String[] args) throws Exception&#123; for (int i = 0; ; i++) &#123; Class c = cp.makeClass(&quot;com.myown.demo.Generated&quot; + i).toClass(); &#125; &#125;&#125; 在这个例子中，源代码在运行时遍历循环生成类。所有生成的类定义都位于Metaspace中。类生成的工作交由javassist负责。 代码持续生成新类，并把它们的定义装载到Metaspace中，直到元数据空间被全部使用，java.lang.OutOfMemoryError: Metaspace异常被触发。当用-XX:MaxMetaspaceSize=64m在Ubuntu16.04.3, java 1.8.0_151，一共加载了66126个类，程序才挂掉。试验得出的完整错误信息如下：12345678910111213141516Exception in thread &quot;main&quot; javassist.CannotCompileException: by java.lang.OutOfMemoryError: Metaspace at javassist.ClassPool.toClass(ClassPool.java:1085) at javassist.ClassPool.toClass(ClassPool.java:1028) at javassist.ClassPool.toClass(ClassPool.java:986) at javassist.CtClass.toClass(CtClass.java:1079) at Metaspace.main(Metaspace.java:8)Caused by: java.lang.OutOfMemoryError: Metaspace at java.lang.ClassLoader.defineClass1(Native Method) at java.lang.ClassLoader.defineClass(ClassLoader.java:763) at java.lang.ClassLoader.defineClass(ClassLoader.java:642) at sun.reflect.GeneratedMethodAccessor1.invoke(Unknown Source) at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) at java.lang.reflect.Method.invoke(Method.java:498) at javassist.ClassPool.toClass2(ClassPool.java:1098) at javassist.ClassPool.toClass(ClassPool.java:1079) ... 4 more 解决方案第一个解决方案，毫无疑问：OutOfMemoryError是因为Metaspace。如果应用程序将metaspace消耗殆尽，我们可以增大Metaspace的空间。更改程序配置，按照如下进行： -XX:maxMetaspaceSize=512m 上面的配置告诉JVM:Metaspace空间最大允许到512MB。 另外一个解决方案初一看更加简单。我们可以移除Metaspace的大小限制(删除这个参数即可)。但是这样做，将会导致沉重的交换负担，会导致内存分配失败。 你可以通过修改各种启动参数来“快速修复”这些内存溢出错误，但你需要正确区分你是否只是推迟或者隐藏了java.lang.OutOfMemoryError的症状。如果你的应用程序确实存在内存泄漏或者本来就加载了一些不合理的类，那么所有这些配置都只是推迟问题出现的时间而已，实际也不会改善任何东西。 java.lang.OutOfMemoryError:Unable to create new native threadJava应用程序天然支持多线程的。这意味着java实现的程序能一次做几件事情(几乎同时)。甚至只有一个cpu–在从一个窗口拉数据到另外一个窗口的时候，视频同时也在后台不停的播放，因为可以同时执行多个操作。 一个思考多线程的方式就是把他们认为是我们能提交任务给他们执行的工人。如果只有一个工人，那么他/她一次只能做一件事情。但是如果有很多工人的话，他们就能根据你的命令同时做事。 就像这些工人都在物理世界，JVM中的线程完成自己的工作也是需要一些空间的，当有足够多的线程却没有那么多的空间时就会像这样： java.lang.OutOfMemoryError: Unable to create new native thread意味着： Java应用已经到了它所能启动的线程的极限。 原因分析当JVM请求操作系统去创建一个新的线程，操作系统却不能再申请一个新的线程，此时OutOfMemoryError(java.lang.OutOfMemoryError: Unbale to crate new thread))就被触发。线程数目的确切数字是依赖于平台的。如果想找到线程数目的限制，可以运行下面将要提到的例子。 一般来说， 引发java.lang.OutOfMemoryError: Unable to create new native thread异常有以下几种情况： 运行在jvm中的应用程序需要一个新的java线程。 JVM向OS请求创建一个新的线程。 OS试图创建一个新的线程，这个线程需要申请内存。 OS拒绝分配内存给线程，因为32位Java进程已经耗尽内存地址空间(2-4GB内存地址已被命中)或者OS的虚拟内存已经完全耗尽。 java.lang.OutOfMemoryError: Unable to create new native thread异常被触发。 实例下面的代码循环创建和开始线程。当运行代码时，很快就到达操作系统的限制，java.lang.OutOfMemoryError: Unable to create new native thread异常被触发。123456789while(true)&#123; new Thread(new Runnable()&#123; public void run() &#123; try &#123; Thread.sleep(10000000); &#125; catch(InterruptedException e) &#123; &#125; &#125; &#125;).start();&#125; 确切的线程数目限制是依赖于平台的，例如Windows，Linux和Mac OS X如下： 64-bit Mac OS X 10.9, Java 1.7.0_45 – JVM dies after #2031 threads have been created64-bit Ubuntu Linux, Java 1.7.0_45 – JVM dies after #31893 threads have been created64-bit Windows 7, Java 1.7.0_45 – due to a different thread model used by the OS,250000,交换文件到10G,程序非常慢通过一个小测试可以知道线程的极限数目。实际Ubuntu16.04.3 x64, Java 1.8.0_151–JVM dies after 11658 threads have been createdException in thread “main” java.lang.OutOfMemoryError: unable to create new native thread at java.lang.Thread.start0(Native Method) at java.lang.Thread.start(Thread.java:717) at OOM_TestThread.main(OOM_TestThread.java:9)实际的ulimit限制有6w+(63812)，也修改过idea的VM的Xmx,由原先的750m调整到6168，效果也是一样。lj@lj-HP-ProBook-640-G1:~/Downloads/source/java-study/javaUnversailTest$ ulimit -amax user processes (-u) 63812也使用命令行运行，实际数值差不多，都在116xx左右，差别不大。 解决方案有时，我们可以通过增加OS级限制，绕过Unable to create new native thread issue错误。例如你限制了JVM可在用户空间创建的线程数，那么你可以检查并增加这个限制：lj@lj-HP-ProBook-640-G1:~/Downloads$ ulimit -acore file size (blocks, -c) 0…… …… …… …… ……max user processes (-u) 63812到达线程限制预示着程序错误。当应用产生数以千计的线程，有时会产生异常可怕的错误–并没有太多的应用需要巨量的线程数目。解决这个问题的一个方式：执行线程dump，可以理解当时的状况。 java.lang.OutOfMemoryError:Out of swap spacejava程序在启动的时候是有内存限制的。这个限制是用参数-Xmx和其他相似的参数说明。有些情况下，JVM要求的内存比可用的物理内存还大，OS(操作系统)开始交换内存的内容到硬盘。 java.lang.OutOfMemoryError: Out of swap space异常表明：交换空间同样耗尽，并且新的内存申请失败，因为缺少物理内存和交换空间。 原因分析当从堆空间申请字节内存失败，并且堆空间也耗尽的时候，java.lang.OutOfMemoryError: Out of swap space异常将被触发。该错误消息中包含分配失败的大小（以字节为单位）和请求失败的原因。 这个问题往往发生在Java进程已经开始交换的情况下，现代的GC算法已经做得足够好了，当时当面临由于交换引起的延迟问题时，GC暂停的时间往往会让大多数应用程序不能容忍。 java.lang.OutOfMemoryError:Out of swap space?往往是由操作系统级别的问题引起的，例如： 操作系统配置的交换空间不足。 系统上的另一个进程消耗所有内存资源。 还有可能是本地内存泄漏导致应用程序失败，比如：应用程序调用了native code连续分配内存，但却没有被释放回操作系统。 解决方案解决这个问题有几个办法，通常最简单的方法就是增加交换空间，不同平台实现的方式会有所不同，比如在Linux下可以通过如下命令实现：先用free -m查看交换空间定义的是多少swapoff -a –关闭交换区dd if=/dev/zero of=swapfile bs=1024 count=655360–根目录下创建一个名为swapfile,大小640Mmkswap swapfile–将swapfile设置为swap区swapon swapfile–启用交换区 Java GC会扫描内存中的数据，如果是对交换空间运行垃圾回收算法会使GC暂停的时间增加几个数量级，因此你应该慎重考虑使用上文增加交换空间的方法。 如果你的应用程序部署在JVM需要同其他进程激烈竞争获取资源的物理机上，建议将服务隔离到单独的虚拟机中但在许多情况下，您唯一真正可行的替代方案是： 升级机器以包含更多内存 优化应用程序以减少其内存占用 当您转向优化路径时，使用内存转储分析程序来检测内存中的大分配是一个好的开始。 java.lang.OutOfMemoryError:Requested array size exceeds VM limitJava对应用程序可以分配的最大数组大小有限制。不同平台限制有所不同，但通常在1到21亿个元素之间。 当你遇到Requested array size exceeds VM limit错误时，意味着你的应用程序试图分配大于Java虚拟机可以支持的数组。 原因分析该错误由JVM中的native code抛出。 JVM在为数组分配内存之前，会执行特定于平台的检查：分配的数据结构是否在此平台中是可寻址的。 你很少见到这个错误是因为Java数组的索引是int类型。 Java中的最大正整数为2 ^ 31 - 1 = 2,147,483,647。 并且平台特定的限制可以非常接近这个数字，例如：我的环境上(64位macOS，运行Jdk1.8)可以初始化数组的长度高达2,147,483,645（Integer.MAX_VALUE-2）。如果再将数组的长度增加1到Integer.MAX_VALUE-1会导致熟悉的OutOfMemoryError：Exception in thread “main” java.lang.OutOfMemoryError: Requested array size exceeds VM limit但是，在使用OpenJDK 6的32位Linux上，在分配具有大约11亿个元素的数组时，您将遇到Requested array size exceeded VM limit的错误。 要理解你的特定环境的限制，运行下文中描述的小测试程序。 示例12345678for (int i = 3; i &gt;= 0; i--) &#123; try &#123; int[] arr = new int[Integer.MAX_VALUE-i]; System.out.format(&quot;Successfully initialized an array with %,d elements.\\n&quot;, Integer.MAX_VALUE-i); &#125; catch (Throwable t) &#123; t.printStackTrace(); &#125;&#125; 该示例重复四次，并在每个回合中初始化一个长原语数组。 该程序尝试初始化的数组的大小在每次迭代时增加1，最终达到Integer.MAX_VALUE。 现在，当使用Hotspot 7在64位Mac OS X上启动代码片段时，应该得到类似于以下内容的输出：java.lang.OutOfMemoryError: Java heap space at eu.plumbr.demo.ArraySize.main(ArraySize.java:8)java.lang.OutOfMemoryError: Java heap space at eu.plumbr.demo.ArraySize.main(ArraySize.java:8)java.lang.OutOfMemoryError: Requested array size exceeds VM limit at eu.plumbr.demo.ArraySize.main(ArraySize.java:8)java.lang.OutOfMemoryError: Requested array size exceeds VM limit at eu.plumbr.demo.ArraySize.main(ArraySize.java:8)注意，在出现Requested array size exceeded VM limit之前，出现了更熟悉的java.lang.OutOfMemoryError: Java heap space。 这是因为初始化2 ^ 31-1个元素的数组需要腾出8G的内存空间，大于JVM使用的默认值。 解决方案java.lang.OutOfMemoryError:Requested array size exceeds VM limit可能会在以下任一情况下出现：数组增长太大，最终大小在平台限制和Integer.MAX_INT之间你有意分配大于2 ^ 31-1个元素的数组在第一种情况下，检查你的代码库，看看你是否真的需要这么大的数组。也许你可以减少数组的大小，或者将数组分成更小的数据块，然后分批处理数据。在第二种情况下，记住Java数组是由int索引的。因此，当在平台中使用标准数据结构时，数组不能超过2 ^ 31-1个元素。事实上，在编译时就会出错：error：integer number too large。 java.lang.OutOfMemoryError:Kill process or sacrifice child为了理解这个错误，我们需要补充一点操作系统的基础知识。操作系统是建立在进程的概念之上，这些进程在内核中作业，其中有一个非常特殊的进程，名叫“内存杀手（Out of memory killer）”。当内核检测到系统内存不足时，OOM killer被激活，然后选择一个进程杀掉。哪一个进程这么倒霉呢？选择的算法和想法都很朴实：谁占用内存最多，谁就被干掉。如果你对OOM Killer感兴趣的话，建议你阅读参考资料2中的文章。 OOM Killer，当可用虚拟虚拟内存(包括交换空间)消耗到让整个操作系统面临风险时，就会产生Out of memory:Kill process or sacrifice child错误。在这种情况下，OOM Killer会选择“流氓进程”并杀死它。 原因分析默认情况下，Linux内核允许进程请求比系统中可用内存更多的内存，但大多数进程实际上并没有使用完他们所分配的内存。这就跟现实生活中的宽带运营商类似，他们向所有消费者出售一个100M的带宽，远远超过用户实际使用的带宽，一个10G的链路可以非常轻松的服务100个(10G/100M)用户，但实际上宽带运行商往往会把10G链路用于服务150人或者更多，以便让链路的利用率更高，毕竟空闲在那儿也没什么意义。 Linux内核采用的机制跟宽带运营商差不多，一般情况下都没有问题，但当大多数应用程序都消耗完自己的内存时，麻烦就来了，因为这些应用程序的内存需求加起来超出了物理内存（包括 swap）的容量，内核（OOM killer）必须杀掉一些进程才能腾出空间保障系统正常运行。就如同上面的例子中，如果150人都占用100M的带宽，那么总的带宽肯定超过了10G这条链路能承受的范围。 示例当你在Linux上运行如下代码：12345678910public static void main(String[] args)&#123; List&lt;int[]&gt; l = new java.util.ArrayList(); for (int i = 10000; i &lt; 100000; i++) &#123; try &#123; l.add(new int[100000000]); &#125; catch (Throwable t) &#123; t.printStackTrace(); &#125; &#125;&#125; 在Linux的系统日志中/var/log/kern.log会出现以下日志：Jun 4 07:41:59 plumbr kernel: [70667120.897649] Out of memory: Kill process 29957 (java) score 366 or sacrifice childJun 4 07:41:59 plumbr kernel: [70667120.897701] Killed process 29957 (java) total-vm:2532680kB, anon-rss:1416508kB, file-rss:0kB注意：你可能需要调整交换文件和堆大小，否则你将很快见到熟悉的Java heap space异常。在作者的测试用例中，使用-Xmx2g指定的2g堆，并具有以下交换配置： 解决方案解决这个问题最有效也是最直接的方法就是升级内存，其他方法诸如：调整OOM Killer配置、水平扩展应用，将内存的负载分摊到若干小实例上….. 我们不建议的做法是增加交换空间。当您回想起 Java 是一种垃圾收集的语言时, 这个解决方案似乎已经不那么有利可图了。现代 GC 算法在物理内存中运行时效率很高, 但是在处理交换空间分配时, 效率很差。交换可以增加几个数量级的GC暂停的长度, 因此在跳转到此解决方案之前, 您应该三思而后行。","categories":[{"name":"Java","slug":"Java","permalink":"https://roclli.github.io/categories/Java/"}],"tags":[{"name":"OOM; Java内存溢出; OutOfMemoryError","slug":"OOM-Java内存溢出-OutOfMemoryError","permalink":"https://roclli.github.io/tags/OOM-Java内存溢出-OutOfMemoryError/"}]},{"title":"(原创)查询log中每小时或者指定小时，错误类型的数量","slug":"log-check","date":"2017-12-11T05:05:21.000Z","updated":"2017-12-13T06:34:54.060Z","comments":true,"path":"2017/12/11/log-check/","link":"","permalink":"https://roclli.github.io/2017/12/11/log-check/","excerpt":"","text":"In a log file with contents as [ERROR_NO] [MESSAGE]- Human readable text display summary/count of specific error numbers that occurred every hour or a specific hour. 假设一个log文件名为application.log，且格式为：(实测中发现有可能因为log文件数据不正常，导致统计结果不一致) 2017-11-22 07:29:45.489 INFO com.aaa.bbb.ccc.dubboservice.impl.BingGenTfoTaskServiceImpl [DubboServerHandler-1.2.3.4:18080-thread-199] zzzzAaaAaaaaaa:结束生成aaaaaa,zzzzzz是:56661 2017-11-22 07:29:45.489 ERROR com.aaaaa.aaa.aaa.dubboservice.impl.BingGenTfoTaskServiceImpl [DubboServerHandler-1.2.3.4:18080-thread-199] zzzzAaaAaaaaaa:结束生成bbbbbb,qwerty是:56661 …… 执行脚本如下：123456789lj@lj-HP-ProBook-640-G1:~/linux-study$ ./getstatic_byhour.sh application.log ERROR没有收到第三个参数，将搜集所有小时的数据---all ERROR hava times:31132017-11-22 07 have ERROR times:302017-11-22 08 have ERROR times:60...... 2017-11-24 15 have ERROR times:10lj@lj-HP-ProBook-640-G1:~/linux-study$ ./getstatic_byhour.sh application.log ERROR &apos;2017-11-24 09&apos;2017-11-24 09 have ERROR times:60 实现脚本如下：12345678910111213141516171819202122232425262728293031323334353637383940lj@lj-HP-ProBook-640-G1:~/Downloads/source/linux-study$ cat getstatic_byhour.sh#!/bin/bashlog_name=&quot;&quot;error_style=&quot;&quot;by_hour=&quot;&quot;function printhelp()&#123; echo &apos;there is no para.invoke sample is:&apos; echo &apos;&apos;$0&apos; log_folder|log_name error_style [2017-11-24 09]&apos; echo &apos;if there is no hour, will display every hour&apos;&#125;if [ $# -lt 2 ]; then printhelp exitelse if [ &quot;$1&quot; ]; then log_name=&quot;$1&quot; fi if [ &quot;$2&quot; ]; then error_style=&quot;$2&quot; fi if [ &quot;$3&quot; ]; then by_hour=&quot;$3&quot; strr=`grep -caP &quot;^$&#123;by_hour&#125;:\\d&#123;2&#125;:\\d&#123;2&#125;.\\d&#123;3&#125; $&#123;error_style&#125;&quot; $&#123;log_name&#125;` echo &quot;$&#123;by_hour&#125; have $&#123;error_style&#125; times:&quot;$&#123;strr&#125; else echo &apos;没有收到第三个参数，将搜集所有小时的数据&apos; by_hour=&quot;&quot; strr=`grep -caP &quot;^\\d&#123;4&#125;-\\d&#123;2&#125;-\\d&#123;2&#125; \\d&#123;2&#125;:\\d&#123;2&#125;:\\d&#123;2&#125;.\\d&#123;3&#125; $&#123;error_style&#125;&quot; $&#123;log_name&#125;` echo &quot;---all $&#123;error_style&#125; hava times:&quot;$&#123;strr&#125; grep -aP &quot;\\d&#123;4&#125;-\\d&#123;2&#125;-\\d&#123;2&#125; \\d&#123;2&#125;:\\d&#123;2&#125;:\\d&#123;2&#125;.\\d&#123;3&#125;&quot; $&#123;log_name&#125; | awk -F&apos;:&apos; &apos;&#123;print $1&#125;&apos; | uniq | sort &gt; tempgrep.txt while read line do strr=`grep -caP &quot;^$&#123;line&#125;:\\d&#123;2&#125;:\\d&#123;2&#125;.\\d&#123;3&#125; $&#123;error_style&#125;&quot; $&#123;log_name&#125;` echo &quot;$&#123;line&#125; have $&#123;error_style&#125; times:&quot;$&#123;strr&#125; done &lt; tempgrep.txt rm -f ./tempgrep.txt fifiexit","categories":[{"name":"shell","slug":"shell","permalink":"https://roclli.github.io/categories/shell/"}],"tags":[{"name":"grep; linux shell; log file check","slug":"grep-linux-shell-log-file-check","permalink":"https://roclli.github.io/tags/grep-linux-shell-log-file-check/"}]},{"title":"Hello World","slug":"hello-world","date":"2017-12-11T03:44:07.555Z","updated":"2017-12-11T03:44:07.555Z","comments":true,"path":"2017/12/11/hello-world/","link":"","permalink":"https://roclli.github.io/2017/12/11/hello-world/","excerpt":"","text":"Welcome to Hexo! This is your very first post. Check documentation for more info. If you get any problems when using Hexo, you can find the answer in troubleshooting or you can ask me on GitHub. Quick StartCreate a new post1$ hexo new \"My New Post\" More info: Writing Run server1$ hexo server More info: Server Generate static files1$ hexo generate More info: Generating Deploy to remote sites1$ hexo deploy More info: Deployment","categories":[],"tags":[]}]}